<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>kafka - Tag - 👨‍💻꿈꾸는 태태태의 공간</title><link>https://taetaetae.github.io/tags/kafka/</link><description>kafka - Tag - 👨‍💻꿈꾸는 태태태의 공간</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sun, 19 Feb 2023 23:39:22 +0900</lastBuildDate><atom:link href="https://taetaetae.github.io/tags/kafka/" rel="self" type="application/rss+xml"/><item><title>KAFKA 서비스 활용 스터디 사례 밋업 후기</title><link>https://taetaetae.github.io/posts/kafka-service-utilization-study-case-review/</link><pubDate>Sun, 19 Feb 2023 23:39:22 +0900</pubDate><author>Author</author><guid>https://taetaetae.github.io/posts/kafka-service-utilization-study-case-review/</guid><description><![CDATA[<div class="featured-image">
                <img src="/images/kafka-meetup-2019/kafka.jpg" referrerpolicy="no-referrer">
            </div>필자는 오프라인에서 진행하는 밋업이나 콘퍼런스 가는 것을 좋아한다. 발표하는 내용을 전부다 이해해서 듣고 온다는 건 거짓말이겠지만 간혹 들었던 내용을 팀 내에 적용해 본다거나 몰랐던 내용에 대해 알게 되는 경우가 많았다. 특히, 질문을 꼭 하는 편인데 질문을 하려고 하면 좀 더 집중해서 듣게 되거나 질문한 세션의 내용은 꽤 오랫동안 기억에 남게 되니 개발자 행사에 참석하면 꼭 질문을 하자는 게 필자 자신과의 약속 중에 하나이기도 하다.
　한동안 코로나로 모든 개발자 행사가 온라인으로 진행하는 등 오프라인 행사는 눈을 씻고 찾기란 하늘에 별 따기였다. 오프라인 행사에 참여하면 나름의 개발력(?)을 얻을 수 있었는데 오프라인 행사 자체를 하지 않아 괜히 기운이 빠지던 요 몇 년이었지 않았나 싶다. 그러다 페이스북 KAFKA 한국 사용자 모임에서 공지가 올라왔고 세션들을 보아하니 하나도 알아듣지 못할(?) 엄청나게 고차원의 내용이 아닌 그럭저럭 이해할 만한 내용으로 준비되어 있었고, 무엇보다 회사와 가까워서 설레는 마음으로 신청을 하였다. 오래전에도 한번 밋업에 참석한 적이 있었는데 나름 진행도 매끄러웠고 좋았던 기억들뿐이라 한 치의 망설임 없이 신청하게 되었다.
신입사원때 자주 오가던 다리&hellip;" 신입사원때 자주 오가던 다리&hellip;  　오전 근무만 하고 판교 테크노벨리에 있는 유명한 다리인 이직의 다리를 건너 SKT/SKP 판교 사옥 1층으로 걸어간다. 판교에 올 일이 잘 없는 게 올 때마다 느끼는 건 정말 IT 회사가 많다는 것. 뭔가 이직을 하려고 마음을 먹지 않아도 괜히 마음이 바운스 거리는 건 기분탓 일까 싶다.
밋업의 분위기 　이런 행사에 가면 맨 앞에 자리를 잡곤 해서 처음엔 몰랐는데 행사 진행 중간에 보니 사회자분 이야기로는 약 90여 명 정도가 왔다고 했다. 오프라인 행사라 그런 건지, 판교 직장인분들의 접근성이 좋아서인지, 아님 정말 KAFKA의 인기(?)가 좋아서 인지는 모르겠지만 예상보다 꽤 많이 와서 조금 놀랬다. 입구에 커피와 쿠키가 제공되었고 개발자 노트북에 덕지덕지 붙일 수 있는 개발자 스티커도 받을 수 있었다.
　이번에는 데보션(Devocen) 이라는 곳에서 후원을 받아 진행한다고 했다. 처음에 데보션이 뭐 하는 곳인지에 대한 간략한 소개와 나중에 추첨을 하기 위해 앱을 설치하라는 귀여운 홍보도 있었다. SK 내/외부 우수 인재가 모여 전문 기술 지식/정보를 등록/축적 하고 공유 교류를 하며 전파 및 확산에 집중을 한다고 한다. 테크 세미나가 월 1회 있다고 하니 종종 들어와 봐야 겠다는 생각을 해본다.
　카프카 모임을 이끄시는 고승범 님도 오셨다. 예전 밋업에서도 뵙긴 했지만 최근에 카프카 관련 책도 새롭게 내시고 그룹도 운영 중이신 분이다. 나는 과연 저러한 열정이 있었나? 있을 수 있나? 라는 생각을 잠시 해본다.
발표 요약 　하나부터 열까지 받아쓰기 수준으로 적진 못했지만 그래도 메모장에 남아있는 기록들을 정리 및 요약해 본다. 오랜만의 오프라인 행사라 들떠서인지 잘못된 기록이 있을 수 있음을 알린다 ^^;
Kafka MirrorMaker로 카오스 엔지니어링 맛보기 / 황한희 님  Kafka MirrorMaker? - 카프카 클러스터를 대상으로 데이터를 mirroring 하는 기능 (토픽 데이터 동기화) 활용방식 : fan-out, aggregation, active-active, acitve-passive 카오스 엔지니어링 : 운영환경에서도 갑작스러운 장애를 견딜 수 있는 시스템을 구축하기 위해 시스템을 실험하는 분야, 장애를 미리 경험  https://en.wikipedia.org/wiki/Chaos_engineering   Chaos Monkey  넷플릭스 개발팀의 운영 원칙으로부터 시작해 현재는 가장 대표적인 카오스 테스팅 도구 마치 무기를 든 원숭이를 데이터 센터에 풀어 놓은것 같다는 의미에서 출발   Pumba  컨테이너 환경에서 제공되는 카오스 엔지니어링 도구 영화 라이온킹에 등장하는 멧돼지인 품바의 멍청하고 산만하다는 특징에서 영감을 받음 비교적 단순한 테스팅을 할 때 유용한 도구   카오스 엔지니어링 파이프라인  안정화 정의 : 기술적인 이슈나 아닌 비즈니스 관점의 지표를 안정된 상태의 지표로 설정 이벤트 선정 : 발생 가능성이 있는 이벤트 선정 실행 : 카오스 엔지니어링 수행 , 실제로 이벤트를 발생시켜보고 가설을 시험 분석    　이번에도 어김없이 질문을 했다.]]></description></item><item><title>KafkaKRU(Kafka 한국사용자 모임) 밋업 후기</title><link>https://taetaetae.github.io/2019/03/31/kafka-meetup-2019/</link><pubDate>Sun, 31 Mar 2019 01:49:30 +0000</pubDate><author>Author</author><guid>https://taetaetae.github.io/2019/03/31/kafka-meetup-2019/</guid><description><![CDATA[<div class="featured-image">
                <img src="/images/kafka-meetup-2019/kafka.jpg" referrerpolicy="no-referrer">
            </div>필자는 ElasticStack을 사용하면서 처음 카프카를 접하게 되었다. 메세징 큐 라는 개념도 전혀 모르는 상태에서 설치부터 ElasticStack 연동까지 사용하며 정말 강제로 카프카에 대해 공부를 하게 되었다. 카프카를 자주 다루고 메커니즘에 대해 자세히 살펴보다 잠깐 해이해질 무렵 카프카 한국 사용자 모임에서 밋업을 한다고 하길래 빛의 속도로 신청, 아마도 1등으로 신청했지 않았을까 싶다.사실 작년 카프카 밋업을 못간게 너무 한(?)이 되어 이번엔 회사 업무 등 여러가지로 한창 바쁘지만 &ldquo;지금이 아니면 안돼&rdquo; 라는 생각으로 밋업을 다녀왔고, 짧지만 후기를 작성해 보고자 한다.
 (요즘 왜 이렇게 바쁜지 모르겠지만&hellip; 신기하게도 그 바쁜 일정들이 하나도 겹치지 않는게 더 신기하다&hellip; )
 삼성 SDS 건물에서 진행된 카프카 밋업" 삼성 SDS 건물에서 진행된 카프카 밋업  참고로 필자는 카프카에 대해 아주 조금 건드려본 수준이라 발표하시는 분들의 전부를 습득하기엔 다소 그릇이 작아서 일부 세션은 거의 &ldquo;그런가보다~&rdquo; 하고 들을 수 밖에 없었다. 후기도 아마 그런 맥락으로 작성할듯 싶다.
 Kafka 한국 사용자 모임 링크 : https://www.facebook.com/groups/kafka.kru  카프카를 활용한 캐시 로그 처리 - 김현준(카카오)  이미지 등 캐시서버의 로그를 분석하기 위한 시스템을 구축하는데 ElasticStack 을 활용 Elasticsearch 로 늦게 들어와서 사례를 찾아보니 대용량 로깅 처리시 앞단에 메세징 큐를 둬야 한다고 했고 그게 카프카 카프카 모니터링은 그라파나로 활용 lag이 자꾸 생김  파티션을 쪼개거나, 컨슈머를 늘리는 방법이 있음 auto.commit.interval.ms 와 enable.auto.commit=true 로 조정 interval을 줄이니 lag이 줄어듬   현재는 수백대 캐시서버의 로그를 초당 15만건 이상 처리중  질문을 했다. 필자도 lag이 높아지면 어쩌지 하는 불안감과 높아지면 컨슈머를 늘리면 되겠지 하는 막연함이 있었는데 commit interval을 줄이면 lag이 줄어든다고 해서 무조건 줄이면 좋은가에 답변은 카프카를 관리하는 주키퍼쪽에 무리가 간다고 설명해 주셨다. 역시 만병통치약은 없고 상황에 따라 적절하게 시스템 관리자가 조정해가며 운영해야 하는점을 느꼈다.
 참고 URL : https://kafka.apache.org/documentation/#adminclientconfigs  카프카를 활용한 엘라스틱서치 실무프로젝트 소개 - 이은학(메가존)  카드사의 프로젝트를 약 3개월간 개발하였고 전체 아키텍쳐 중에 일부분을 kakfa를 활용 Elasticsearch 데이터를 hadoop에 백업 형태로 옮기며 관리 filebeat &gt; kafka &gt; spark streaming 을 활용하여 데이터의 검증처리가 가능 (특정 상황에서의 관리자에게 알림 등) logstash 의 ruby 필터를 활용하여 일정의 작업을 해주는 데이터 파이프라인 구성 가능 (개인정보 식별 등) logstash 는 cron형태의 배치로도 가능  또 질문을 하였다. (카프카 밋업과는 무관했지만&hellip;) logastsh 를 사용하면서 필터쪽에 로직이 들어가면 성능상 괜찮냐는 질문에 하루에 15억건을 처리하고있고 문제가 없었다고 한다. 필자는 아파치 엑세스 로그를 logstash로 처리하면서 간혹 뻗거나 에러가 발생했는데 아마 파일을 logstash가 직접 바라보고 처리도 하게해서 그런것 같다. (지금은 filebeat가 shipper 역활을 수행하고 있고 큰 무리 없이 운영중)
카프카를 활용한 rabbitMQ 로그처리 - 정원빈 (카카오)  레빗엠큐는 erlang으로 구현된 AMQP 메시지 브로커이고 TCP기반으로 구성 Kafka 는 게으르지만 메우 효율성이 뛰어남, 반면 RabbitMQ 는 똑똑하지만 보다 느림 Kafka 에서 Elasticsearch 로의 ingset 는 NIFI를 활용 레빗엠큐와 카프카의 차이     Kafka RabbitMQ     컨슈머 추가 여러 컨슈머가 하나의 메세지를 동시에 할수 있어 확장에 용이함 확장할때마다 큐를 추가 생성해야함   메세지 저장 로그기반으로 디스크에 저장, 리텐션 이후 삭제 큐 기반으로 메모리에 저장 컨슈머가 메세지 수신시 즉시 삭제   메세지 처리 발송확인 가능 / 수신확인 불가능 발송확인/수신확인 가능      카프카를 마이크로서비스 아키텍쳐에 활용하기 - 이동진 (아파치 소프트웨어 파운데이션)  카프카 스트림즈 소개 (Interactive Query) 카프카를 활용하여 마이크로서비스에서 사용하려면 데이터를 임시 공간에 넣어두고 (redis 같은?]]></description></item><item><title>아파치 엑세스 로그를 엘라스틱서치에 인덱싱 해보자.</title><link>https://taetaetae.github.io/2018/01/25/apache-access-log-to-es/</link><pubDate>Thu, 25 Jan 2018 21:18:35 +0000</pubDate><author>Author</author><guid>https://taetaetae.github.io/2018/01/25/apache-access-log-to-es/</guid><description><![CDATA[apache access log 를 분석하고 싶은 상황이 생겼다. 아니 그보다 apache access에 대해서 실시간으로 보고싶었고, log를 검색 &amp; 데이터를 가공하여 유의미한 분석결과를 만들어 보고 싶었다. 그에 생각한것이 (역시) ElasticStack.처음에 생각한 방안은 아래 그림처럼 단순했다. 처음 생각한 단순한 구조" 처음 생각한 단순한 구조 
하지만, 내 단순한(?) 예상은 역시 빗나갔고 logstash에서는 다음과 같은 에러를 내뱉었다.
 retrying individual bulk actions that failed or were rejected by the previous bulk request
 request가 많아짐에 따라 elasticsearch가 버벅거리더니 logstash에서 대량작업은 거부하겠다며 인덱싱을 멈췄다. 고민고민하다 elasticsearch에 인덱싱할때 부하가 많이 걸리는 상황에서 중간에 버퍼를 둔 경험이 있어서 facebook그룹에 문의를 해봤다. https://www.facebook.com/groups/elasticsearch.kr/?multi_permalinks=1566735266745641 역시 나보다 한참을 앞서가시는 분들은 이미 에러가 뭔지 알고 있으셨고, 중간에 버퍼를 두고 하니 잘된다는 의견이 있어 나도 따라해봤다. 물론 답변중에 나온 redis가 아닌 기존에도 비슷한 구조에서 사용하고 있던 kafka를 적용. 아, 그전에 현재구성은 Elasticsearch 노드가 총 3대로 클러스터 구조로 되어있는데 노드를 추가로 늘리며 스케일 아웃을 해보기전에 할수있는 마지막 방법이다 생각하고 중간에 kafka를 둬서 부하를 줄여보고 싶었다. (언제부턴가 마치 여러개의 톱니바퀴가 맞물려 돌아가는듯한 시스템 설계를 하는게 재밌었다.) 아래 그림처럼 말이다.
그나마 좀더 생각한 구조" 그나마 좀더 생각한 구조  그랬더니 거짓말 처럼 에러하나 없이 잘 인덱싱이 될수 있었다. logstash가 양쪽에 있는게 약간 걸리긴 하지만, 처음에 생각한 구조보다는 에러가 안나니 다행이라 생각한다.
이 구조를 적용하면서 얻은 Insight가 있기에, 각 항목별로 적어 보고자 한다. ( 이것만 적어놓기엔 너무 없어보여서.. )
access log 를 어떻게 분석하여 인덱싱 할것인가? apache 2.x를 사용하고 별도의 로그 포맷을 정하지 않으면 아래와 같은 access log가 찍힌다. 123.1.1.1 - - [25/Jan/2018:21:55:35 +0900] &quot;GET /api/test?param=12341234 HTTP/1.1&quot; 200 48 1144 &quot;http://www.naver.com/&quot; &quot;Mozilla/5.0 (iPhone; CPU iPhone OS 11_1_2 like Mac OS X) AppleWebKit/604.3.5 (KHTML, like Gecko) Mobile/15B202 NAVER(inapp; blog; 100; 4.0.44)&quot; 그럼 이 로그를 아무 포맷팅 없이 로깅을 하면 그냥 한줄의 텍스트가 인덱싱이 된다. 하지만 이렇게 되면 elasticsearch 데이터를 다시 재가공하거나 별도의 작업이 필요할수도 있으니 중간에 있는 logstash에게 일을 시켜 좀더 nice 한 방법으로 인덱싱을 해보자. 바로 logstash 의 filter 기능이다. 그중 Grok filter 라는게 있는데 패턴을 적용하여 row data 를 필터링하는 기능이다. 조금 찾아보니 너무 고맙게도 아파치 필터 예제가 있어 수정하여 적용할수 있었다. http://grokconstructor.appspot.com/do/match?example=2 그래서 적용한 필터설정은 다음과 같다.
filter { grok { match =&gt; { message =&gt; &#34;%{IP:clientIp} (?:-|) (?:-|) \[%{HTTPDATE:timestamp}\] \&#34;(?:%{WORD:httpMethod} %{URIPATH:uri}%{GREEDYDATA}(?: HTTP/%{NUMBER})?|-)\&#34; %{NUMBER:responseCode} (?:-|%{NUMBER})&#34; } } } 이렇게 하고 elasticsearch 에 인덱싱을 하면 키바나에서 다음과 같이 볼수 있다. 키바나에 내가 원하는 구조대로 이쁘게 들어가 있는 access log" 키바나에 내가 원하는 구조대로 이쁘게 들어가 있는 access log 
각 필드가 아닌 한줄로 인덱싱이 되어버린다. Elasticsearch 에 인덱싱이 되긴 하는데 로그 한줄이 통째로 들어가 버린다. message라는 이름으로&hellip; 알고보니 현재 구조는 logstash가 kafka 앞 뒤에 있다보니 producer logstash 와 consumer logstash 의 codec이 맞아야 제대로 인덱싱이 될수 있었다. 먼저 access log에서 kafka 로 produce 하는 logstash 에서는 output 할때 codec 을 맞춰주고
output { kafka { bootstrap_servers =&gt; &#34;123.1.2.3:9092,123.1.2.4:9092&#34; topic_id =&gt; &#34;apache-log&#34; codec =&gt; json{} } } kafka 에서 consume 하는 logstash 에서는 input 에서 codec 을 맞춰준다.
input { kafka { bootstrap_servers =&gt; &#34;123.1.2.3:9092,123.1.2.4:9092&#34; topic_id =&gt; &#34;apache-log&#34; codec =&gt; json{} } } 그렇게 되면 codec이 맞아 각 필드로 이쁘게 인덱싱을 할수 있게 되었다.
필요없는 uri는 제외하고 인덱싱할수 있을까? /으로는 uri 라던지 /server-status같이 알고있지만 인덱싱은 하기 싫은 경우는 간단하게 아래처럼 if문으로 제외시킬수 있었다.]]></description></item><item><title>What is Kafka?</title><link>https://taetaetae.github.io/2017/11/02/what-is-kafka/</link><pubDate>Thu, 02 Nov 2017 21:30:13 +0000</pubDate><author>Author</author><guid>https://taetaetae.github.io/2017/11/02/what-is-kafka/</guid><description>&lt;div class="featured-image">
&lt;img src="/images/what-is-kafka/kafka.png" referrerpolicy="no-referrer">
&lt;/div>필자가 맡고있는 서비스에 Elastic Stack 을 도입하면서 중간에 버퍼가 필요하여 Message-Queue 시스템들을 알아보던 중 Kafka 에 대해 알아보고, 정리를 해보게 된다.
기본설명 및 기존 메세징 시스템과 다른점 메세징 큐의 일종 말 그대로 분산형 스트리밍 플랫폼, LinkedIn에서 여러 구직 + 채용 정보들을 한곳에서 처리(발행/구독)할수 있는 플랫폼으로 개발이 시작 대용량의 실시간 로그 처리에 특화되어 설계된 메시징 시스템, 기존 범용 메시징 시스템대비 TPS가 매우 우수 메시지를 기본적으로 메모리에 저장하는 기존 메시징 시스템과는 달리 메시지를 파일 시스템에 저장 → 카프카 재시작으로 인한 메세지 유실 우려 감소 기존의 메시징 시스템에서는 broker가 consumer에게 메시지를 push해 주는 방식인데 반해, Kafka는 consumer가 broker로부터 직접 메시지를 가지고 가는 pull 방식으로 동작하기 때문에 consumer는 자신의 처리능력만큼의 메시지만 broker로부터 가져오기 때문에 최적의 성능을 낼 수 있다. 카프카 주요 개념 producer : 메세지 생산(발행)자. consumer : 메세지 소비자 consumer group : consumer 들끼리 메세지를 나눠서 가져간다.offset 을 공유하여 중복으로 가져가지 않는다. broker : 카프카 서버를 가리킴 zookeeper : 카프카 서버 (+클러스터) 상태를 관리하고 cluster : 브로커들의 묶음 topic : 메세지 종류 partitions : topic 이 나눠지는 단위 Log : 1개의 메세지 offset : 파티션 내에서 각 메시지가 가지는 unique id 카프카는 어떤식으로 돌아가는가 zookeeper 가 kafka 의 상태와 클러스터 관리를 해준다.
정해진 topic 에 producer 가 메세지를 발행해놓으면 consumer 가 필요할때 해당 메세지를 가져간다. (여기서 카프카로 발행된 메세지들은 consumer가 메세지를 소비한다고 해서 없어지는게 아니라 카프카 설정 log.retention.hours(default : 168[7일])에 의해 삭제된다.)
partition 개수와 consumer group 개념 하얀색(consumer-01) : 파티션 개수가 4개인데 비해 컨슈머가 3개, 이렇게 되면 어느 컨슈머가 두개의 파티션을 담당해야하는 상황이 생긴다. 주황색(consumer-02) : 파티션 개수가 4개인데 비해 컨슈머가 5개, 이렇게 되면 하나의 노는(?) 컨슈머가 생기는 상황이 생긴다. 가장 적절한 개수는 정해지지 않았지만 통상 컨슈머그룹의 컨슈머 개수와 파티션 개수를 동일하게 가져가곤 한다. 참고 url http://kafka.apache.org/ http://www.popit.kr/author/peter5236/ http://jinhokwon.tistory.com/168 http://programist.tistory.com/entry/Apache-Kafka-클러스터링-구축-및-테스트 https://www.elastic.co/kr/blog/just-enough-kafka-for-the-elastic-stack-part1 https://www.slideshare.net/springloops/apache-kafka-intro20150313springloops-46067669</description></item></channel></rss>