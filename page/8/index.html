<!doctype html><html lang=en><head><meta name=generator content="Hugo 0.74.3"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><meta http-equiv=x-ua-compatible content="IE=edge, chrome=1"><title>👨‍💻꿈꾸는 태태태의 공간</title><meta name=Description content><meta property="og:title" content="👨‍💻꿈꾸는 태태태의 공간"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://taetaetae.github.io/"><meta property="og:updated_time" content="2024-05-26T22:55:50+09:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="👨‍💻꿈꾸는 태태태의 공간"><meta name=twitter:description content><meta name=application-name content="👨‍💻꿈꾸는 태태태의 공간"><meta name=apple-mobile-web-app-title content="👨‍💻꿈꾸는 태태태의 공간"><meta name=naver-site-verification content="2d1cdbb963ba178aa7cbf58500afc668cae1e645"><meta name=google-site-verification content="vvFCdv0-GuQhEWG8vtNJfA7YSY2HYQ1hpHh9P-a6Pv8"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://taetaetae.github.io/><link rel=alternate href=/index.xml type=application/rss+xml title="👨‍💻꿈꾸는 태태태의 공간"><link rel=feed href=/index.xml type=application/rss+xml title="👨‍💻꿈꾸는 태태태의 공간"><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","url":"https:\/\/taetaetae.github.io\/","inLanguage":"en","author":{"@type":"Person","name":"태태태"},"name":"👨‍💻꿈꾸는 태태태의 공간"}</script></head><body header-desktop=auto header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem('theme')?localStorage.getItem('theme')==='dark':('auto'==='auto'?window.matchMedia('(prefers-color-scheme: dark)').matches:'auto'==='dark'))&&document.body.setAttribute('theme','dark');</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="👨‍💻꿈꾸는 태태태의 공간">👨‍💻꿈꾸는 태태태의 공간</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>Posts </a><a class=menu-item href=/tags/>Tags </a><a class=menu-item href=/categories/>Categories </a><span class="menu-item delimiter"></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="👨‍💻꿈꾸는 태태태의 공간">👨‍💻꿈꾸는 태태태의 공간</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><a class=menu-item href=/posts/>Posts</a><a class=menu-item href=/tags/>Tags</a><a class=menu-item href=/categories/>Categories</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class="page home" posts><div class=home-profile><div class=home-avatar><a href=https://taetaetae.github.io/resume title=resume target=_blank><img class=lazyload src=/svg/loading.min.svg data-src=/images/profile.png data-srcset="/images/profile.png, /images/profile.png 1.5x, /images/profile.png 2x" data-sizes=auto alt=/images/profile.png title=/images/profile.png></a></div><h2 class=home-subtitle><div id=id-1 class=typeit></div></h2><div class=links><a href=https://github.com/taetaetae title=GitHub target=_blank rel="noopener noreffer me"><i class="fab fa-github-alt fa-fw"></i></a><a href=https://linkedin.com/in/taetaetae title=LinkedIn target=_blank rel="noopener noreffer me"><i class="fab fa-linkedin fa-fw"></i></a><a href=https://www.instagram.com/_taetaetae title=Instagram target=_blank rel="noopener noreffer me"><i class="fab fa-instagram fa-fw"></i></a><a href=https://facebook.com/taetaetae0 title=facebook target=_blank rel="noopener noreffer me"><i class="fab fa-facebook fa-fw"></i></a><a href=mailto:taetaetae_@naver.com title=Email rel=me><i class="far fa-envelope fa-fw"></i></a><a href=/index.xml title=RSS target=_blank rel="noopener noreffer me"><i class="fas fa-rss fa-fw"></i></a></div></div><article class="single summary" itemscope itemtype=http://schema.org/Article><div class=featured-image-preview><a href=/2018/02/08/jenkins-sonar-github-integration/><img class=lazyload src=/svg/loading.min.svg data-src=/images/jenkins-sonar-github-integration/concept.png data-srcset="/images/jenkins-sonar-github-integration/concept.png, /images/jenkins-sonar-github-integration/concept.png 1.5x, /images/jenkins-sonar-github-integration/concept.png 2x" data-sizes=auto alt=/images/jenkins-sonar-github-integration/concept.png title=/images/jenkins-sonar-github-integration/concept.png></a></div><h1 class=single-title itemprop="name headline"><a href=/2018/02/08/jenkins-sonar-github-integration/>소나큐브 이용 코드 정적분석 자동화</a></h1><div class=post-meta><span class=post-author><a href=https://taetaetae.github.io/resume title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw"></i>태태태</a></span>&nbsp;<span class=post-publish>published on <time datetime=2018-02-08>2018-02-08</time></span>&nbsp;<span class=post-category>included in <a href=/categories/tech/><i class="far fa-folder fa-fw"></i>Tech</a></span></div><div class=content>코드 정적분석이라 함은 실제 프로그램을 실행하지 않고 코드만의 형태에 대한 분석을 말한다. 이를테면 냄새나는 코드(?)라던지, 위험성이 있는 코드, 미리 정의된 규칙이나 코딩 표준을 준수하는지에 대한 분석을 말하는데 java 기준으로는 아래 다양한 (잘 알려진) 정적분석 도구들이 있다. PMD 미사용 변수, 비어있는 코드 블락, 불필요한 오브젝트 생성과 같은 Defect을 유발할 수 있는 코드를 검사 https://pmd.github.io FindBugs 정해진 규칙에 의해 잠재적인 에러 타입을 찾아줌 http://findbugs.sourceforge.net CheckStyle 정해진 코딩 룰을 잘 따르고 있는지에 대한 분석 http://checkstyle.sourceforge.net 이외에 SonarQube 라는 툴이 있는데 개인적으로 위 알려진 다른 툴들의 종합판(?)이라고 생각이 들었고, 그중 가장 인상깊었던 기능이 github과 연동이 되고 적절한 구성을 하게 되면 코드를 수정하는과 동시에 자동으로 분석을 하고 리포팅까지 해준다는 부분이였다. ( 더 좋은 방법이 있는지는 모르겠으나 다른 도구들은 수동으로 돌려줘야 하고 리포팅 또한 Active하지 못한(?) 아쉬운 점이 있었다. )
지금부터 Jenkins + github web-hook + SonarQube 를 구성하여 코드를 수정하고 PullRequest를 올리게 되면 수정한 파일에 대해 자동으로 정적분석이 이뤄지고, 그에대한 리포팅이 해당 PullRequest에 댓글로 달리도록 설정을 해보겠다. (코드리뷰를 봇(?)이 자동으로 해주는게 얼마나 편한 일인가&mldr;)
기본 컨셉 전체적인 컨셉은 다음 그림과 같다.
전체 컨셉" 전체 컨셉 IDE에서 코드수정을 하고 remote 저장소에 commit & push를 한다. 그 다음 github에서 master(혹은 stable한 branch)에 대해 작업 branch를 PullRequest 올린다. 미리 등록한 github의 web-hook에 의해 PullRequest 정보들을 jenkins에 전송한다. 전달받은 정보를 재 가공하여 SonarQube로 정적분석을 요청한다. SonarQube에서 분석한 정보를 다시 jenkins로 return 해준다. SonarQube으로부터 return 받은 정보를 해당 PullRequest의 댓글에 리포팅을 해준다. 간단히 보면 (뭐 간단하니 쉽네~) 라고 볼수도 있겠지만 나는 이런 전체 흐름을 설정하는데 있어 어려웠다.
사실 셋팅하는 과정에서 적지않은 삽질을 했었기에, 이 포스팅을 적는 이유일수도 있겠다. 더불어 검색을 해봐도 이렇게 전체흐름이 정리된 글이 잘 안보여서 + 내가 한 삽질을 다른 누군가도 할것같아서(?)
Maven 설치 기본적으로 Maven의 H2DB를 사용하므로 SonarQube를 설치하기전에 Maven부터 설치해줘야 한다.
$ wget http://apache.mirror.cdnetworks.com/maven/maven-3/3.5.2/binaries/apache-maven-3.5.2-bin.tar.gz $ tar -zxvf apache-maven-3.5.2-bin.tar.gz (환경변수 셋팅후 ) $ mvn -version Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T16:58:13+09:00) ... SonarQube 설치 정적분석을 도와주는 SonarQube를 설치해보자.
$ wget https://sonarsource.bintray.com/Distribution/sonarqube/sonarqube-6.7.1.zip $ unzip sonarqube-6.7.1.zip $ cd sonarqube-6.7.1/bin/linux-x86-64 $ ./sonar.sh start Starting SonarQube... Started SonarQube. 기본적으로 9000포트를 사용하고 있으니 다른포트를 사용하고자 한다면 /sonarqube-6.7.1/conf/sonar.properties 내 sonar.web.port=9000 을 수정해주면 된다. (SonarQube도 Elasticsearch를 사용하구나&mldr;) 설치후 실행을 한뒤 서버IP:9000을 접속해보면 아래 화면처럼 나온다. (혹시 접속이 안된다거나 서버가 실행이 안된다면 ./sonar.sh console로 로그를 보면 문제해결에 도움이 될수도 있다. )
SonarQube 메인화면" SonarQube 메인화면 SonarQube Scanner 설치 소스를 연동시켜 정적분석을 하기 위해서는 SonarQube Scanner 라는게 필요하다고 한다. 아래 url에서 다운받아 적절한 곳에 압축을 풀어두자. https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner
$ wget https://sonarsource.bintray.com/Distribution/sonar-scanner-cli/sonar-scanner-cli-3.0.3.778-linux.zip $ unzip sonar-scanner-cli-3.0.3.778-linux.zip # jenkins 설치 및 SonarQube 연동 jenkins 설치는 간단하니 별도 언급은 안하고 넘어가&mldr;려고 했으나, 하나부터 열까지 정리한다는 마음으로~ https://jenkins.io/download/ 에서 최신버전을 tomcat/webapps/ 아래에 다운받고 server.xml 을 적절하게 수정해준다.
$ wget http://mirrors.jenkins.io/war-stable/latest/jenkins.war $ vi tomcat/conf/server.xml &lt;Connector port="19001" protocol="HTTP/1.1" # 포트 변경 &lt;Context path="/jenkins" debug="0" privileged="true" docBase="jenkins.war" /> #추가 # tomcat/bin/startup.sh jenkins 설치를 완료 한 후 필요한 플러그인을 추가로 설치해준다.
Python Plugin GitHub Pull Request Builder GitHub plugin 접속 : 서버IP:19001 (참고로 한 서버에서 다 설치하다보니 port 충돌을 신경쓰게되었다. ) 처음 jenkins를 실행하면 이런저런 설정을 하는데 특별한 설정 변경없이 next버튼을 연신 눌러면 설치가 완료 되고, SonarQube를 사용하기 위해 SonarQube Scanner for Jenkins라는 플러그인을 설치해주자.</div><div class=post-footer><a href=/2018/02/08/jenkins-sonar-github-integration/>Read More</a><div class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/sonarqube/>SonarQube</a>,&nbsp;<a href=/tags/jenkins/>jenkins</a>,&nbsp;<a href=/tags/github/>github</a>,&nbsp;<a href=/tags/integration/>integration</a>,&nbsp;<a href=/tags/archives-2018/>archives-2018</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><h1 class=single-title itemprop="name headline"><a href=/2018/02/08/github-web-hook-jenkins-job-excute/>Github의 WebHook을 이용하여 자동 Jenkins Job 실행</a></h1><div class=post-meta><span class=post-author><a href=https://taetaetae.github.io/resume title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw"></i>태태태</a></span>&nbsp;<span class=post-publish>published on <time datetime=2018-02-08>2018-02-08</time></span>&nbsp;<span class=post-category>included in <a href=/categories/tech/><i class="far fa-folder fa-fw"></i>Tech</a></span></div><div class=content>PullRequest가 발생하면 알림을 받고싶다거나, 내가 관리하는 레파지토리에 댓글이 달릴때마다 또는 이슈가 생성될때마다 정보를 저장하고 싶다거나. 종합해보면 Github에서 이벤트가 발생할때 어떤 동작을 해야 할 경우 Github에서 제공하는 Webhook 을 사용하여 목적을 달성할 수 있다. 아 당연한 이야기이지만 언급하고 넘어갈께 있다면, Github에서 Jenkins Job을 호출하기 위해서는 Jenkins가 외부에 공개되어 있어야 한다. (내부사설망이나 private 한 설정이 되어있다면 호출이 안되어 Webhook기능을 사용할 수 없다.)
Jenkins Security 설정 Jenkins Job을 외부에서 URL로 실행을 하기 위해서는 아래 설정이 꼭 필요하다. (이 설정을 몰라서 수많은 삽질을 했다.) CSRF Protection 설정 체크를 풀어줘야 한다. 이렇게 되면 외부에서 Job에 대한 트리거링이 가능해 진다.
Jenkins > Configure Global Security" Jenkins > Configure Global Security Jenkins Job 설정 Github 에서 Webhook에 의해 Jenkins Job을 실행하게 될텐데, 그때 정보들이 payload라는 파라미터와 함께 POST 형식으로 호출이 되기 때문에 미리 Job에서 받는 준비(?)를 해둬야 한다. 설정은 간단하게 다음과 같이 Job 파라미터 설정을 해주면 된다.
Jenkins > 해당 Job > configure" Jenkins > 해당 Job > configure Github Webhook 설정 이제 Github Repository 의 Hook 설정만 하면 끝이난다. 해당 Repository > Settings > Hooks 설정에 들어가서 Add webhook을 선택하여 Webhook을 등록해준다. URL은 {jenkins URL}/jenkins/job/{job name}/buildWithParameters식으로 설정해주고 Content Type 은 application/x-www-form-urlencoded으로 선택한다. 언제 Webhook을 트리거링 시킬꺼냐는 옵션에서는 원하는 설정에 맞추면 되겠지만 나는 pullRequest가 등록 될때만 미리 만들어 놓은 Jenkins Job을 실행시킬 계획이였으니 Let me select individual events.을 설정하고 Pull Request에 체크를 해준다. 아래 그림처럼 말이다.
해당 Repositroy > Settings > Hooks" 해당 Repositroy > Settings > Hooks 이렇게 등록하고 다시 들어가서 맨 아랫 부분Recent Deliveries을 보면 ping test 가 이루어져 정상적으로 응답을 받은것을 확인할수가 있다.
Webhook 등록 결과" Webhook 등록 결과 이렇게 설정을 다 한 뒤 PullRequest를 발생시키면 Jenkins 해당 Job에서는 파라미터를 받으며 실행이 된것을 확인할수가 있다.
Jenkins Job 실행 결과" Jenkins Job 실행 결과 끝~</div><div class=post-footer><a href=/2018/02/08/github-web-hook-jenkins-job-excute/>Read More</a><div class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/jenkins/>jenkins</a>,&nbsp;<a href=/tags/github/>github</a>,&nbsp;<a href=/tags/webhook/>Webhook</a>,&nbsp;<a href=/tags/archives-2018/>archives-2018</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><h1 class=single-title itemprop="name headline"><a href=/2018/02/08/github-with-jenkins/>Github과 Jenkins 연동하기</a></h1><div class=post-meta><span class=post-author><a href=https://taetaetae.github.io/resume title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw"></i>태태태</a></span>&nbsp;<span class=post-publish>published on <time datetime=2018-02-08>2018-02-08</time></span>&nbsp;<span class=post-category>included in <a href=/categories/tech/><i class="far fa-folder fa-fw"></i>Tech</a></span></div><div class=content>Jenkins에서 Github의 소스를 가져와서 빌드를 하는 등 Github과 Jenkins와 연동을 시켜줘야하는 상황에서, 별도의 선행 작업이 필요하다. 다른 여러 방법이 있을수 있는데 여기서는 SSH로 연동하는 방법을 알아보고자 한다.우선 Jenkins가 설치되어있는 서버에서 인증키를 생성하자.
$ ssh-keygen -t rsa -f id_rsa Generating public/private rsa key pair. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in id_rsa. Your public key has been saved in id_rsa.pub. The key fingerprint is: SHA256:~~~~~ ~~~@~~~~~ The key's randomart image is: +---[RSA 2048]----+ | o*+**=*=**+ | | o B=o+o++o | | E+.o+ + oo .| | oo. * o ...| | .+ S = o | | . + o . | | . . . | | . | | | +----[SHA256]-----+ $ ls id_rsa id_rsa.pub 개인키(id_rsa)는 젠킨스에 설정해준다. (처음부터 끝까지 복사, 첫줄 마지막줄 빼면 안된다&mldr; )
젠킨스에 SSH 개인키 설정" 젠킨스에 SSH 개인키 설정 그 다음 공개키(id_rsa.pub)는 Github에 설정을 해준다.
Github에 SSH 공개키 설정" Github에 SSH 공개키 설정 이렇게 한뒤 Jenkins 에서 임의로 job을 생성하고 job 설정 > 소스코드 관리 에서 git 부분에 아래처럼 테스트를 해서 정상적으로 연동이 된것을 확인한다. Credentials 값을 위에서 설정한 개인키로 설정하고, repo 주소를 SSH용으로 적었을때 에러가 안나오면 성공한것이다.
정상 연결되면 Jenkins 오류도 없고, github SSH 키에 녹색불이 들어온다." 정상 연결되면 Jenkins 오류도 없고, github SSH 키에 녹색불이 들어온다. 끝~</div><div class=post-footer><a href=/2018/02/08/github-with-jenkins/>Read More</a><div class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/jenkins/>jenkins</a>,&nbsp;<a href=/tags/github/>github</a>,&nbsp;<a href=/tags/archives-2018/>archives-2018</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><h1 class=single-title itemprop="name headline"><a href=/2018/02/01/linux-selenium/>linux(centOS)에서 selenium 설정하기 (feat. python)</a></h1><div class=post-meta><span class=post-author><a href=https://taetaetae.github.io/resume title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw"></i>태태태</a></span>&nbsp;<span class=post-publish>published on <time datetime=2018-02-01>2018-02-01</time></span>&nbsp;<span class=post-category>included in <a href=/categories/tech/><i class="far fa-folder fa-fw"></i>Tech</a></span></div><div class=content>테스트 코드로 안되는 실제 브라우저단 사용성 테스트를 하고싶은 경우가 있다. 이를테면 화면이 뜨고, 어떤 버튼을 누르면, 어떤 결과가 나와야 하는 일련의 Regression Test. 이때 활용할수 있는게 다양한 도구가 있지만 이번엔 selenium 에 대해서 알아보고자 한다.처음부터 사실 web application 테스트를 하려고 selenium 를 알아보게 된건 아니고, 내가 참여하고 있는 특정 밴드(네이버 BAND)에서 일주일에 한번씩 동일한 형태의 글을 올리고 있는데 (일종의 한주 출석체크 같은&mldr;) 이를 자동화 해볼순 없을까 하며 밴드 API를 찾아보다 selenium 라는것을 알게되었고, 매크로처럼 어떤버튼 누르고 그다음 어떤버튼 누르고 하는 일련의 과정을 코드로 구성할수 있다는 점에 감동을 받아(?) + 별도의 API를 발급받지 않아도 되어 사용하게 되었다. (물론 UI가 바뀌면 골치아프겠지만&mldr;)
여기서는 selenium 이 무엇인지에 대한 설명은 하지 않는다. (인터넷에 나보다 정리 잘된글이 많으니&mldr;) 단, linux 환경에서 셋팅하는 정보가 너무 없고 몇일동안 삽질을 한게 아쉬워서 그 과정을 포스팅 해본다. (나같은 분이 이 글을 보고 도움이 되실꺼라는 기대를 갖으며&mldr;)
※ 주의 : 본 포스팅은 밴드 서비스에 글을 올릴수 있는 비 정상적인 방법의 공유가 아닌, selenium에 대한 사용 후기(?)에 대한 글입니다. (참고로 막혔어요 -ㅁ-)
설정하기 서버 환경은 CentOS 7.4 64Bit + Python 3.6.3 + jdk 8 이다. 우선 selenium 을 설치해준다.
$ sudo python3.6 -m pip install selenium 그 다음 CentOS에서 크롬브라우저를 설치하기 위하여 yum 저장소를 추가한다. (꼭 크롬이 아니더라도 파이어폭스나 지금은 지원이 끊긴 팬텀JS 같은것으로 활용할수도 있으나 다른것들도 해봤는데 자꾸 설정에서 걸려서 크롬에 대한 내용을 포스팅 한다.)
$ sudo vi /etc/yum.repos.d/google-chrome.repo [google-chrome] name=google-chrome baseurl=http://dl.google.com/linux/chrome/rpm/stable/x86_64 enabled=1 gpgcheck=1 gpgkey=https://dl-ssl.google.com/linux/linux_signing_key.pub 그리고는 yum 으로 크롬 브라우저를 설치한다. (내가 설치했을때의 버전은 google-chrome-stable.x86_64 0:64.0.3282.119-1)
$ yum install google-chrome-stable 크롬드라이버를 설치해야한다. 다음 url에서 받을수 있는데 https://sites.google.com/a/chromium.org/chromedriver/downloads 나는 2.35 linux64 버전을 받았다. 다운받고 unzip 하면 딱하나 파일이 있는데 나중에 selenium 을 사용할때 이용되니 path를 알아두자.
그다음 파이썬 코드를 작성한다. 내가 짠 파이썬 코드는 다음과 같은 순서로 실행이 된다.
밴드 접속 ( https://band.us/home ) 로그인 특정 밴드 선택 글쓰기 버튼 누르고 양식에 맞춰 글 작성 글 등록 파이썬 코드는 아래처럼 작성하였다. (중요부분만.. 그 아래는 자유)
from selenium import webdriver from selenium.webdriver.chrome.options import Options # 초기화 -------------------------------------------- chrome_options = Options() chrome_options.add_argument("--headless") driver = webdriver.Chrome(executable_path='home/~~~/chromedriver', chrome_options=chrome_options) driver.implicitly_wait(3) driver.get('https://band.us/home') # 로그인 -------------------------------------------- driver.find_element_by_class_name('_loginLink').click() ...생략 그리고 실행을 해보면 작동이 잘~ 된다. selenium + python 으로 자동작성된 밴드 글" selenium + python 으로 자동작성된 밴드 글
마치며 selenium 에 대해 찾아보면 거의 윈도우 환경에서 돌아가는것들에 대한 포스팅이 많았다. 난 리눅스 환경에서 스케쥴러(젠킨스 같은)를 통해 자동으로 화면없이 작동시키고 싶었는데 아무리 찾아봐도 + 삽질해도 잘 안되었다. 결국 사내에도 나같은 삽질을 하신 분을 찾고 묻고 물어 크롬드라이버만 있어야 하는것이 아니라 크롬앱또한 있어야 동작을 한다는것을 알게 되었다. 역시, 내가 한 삽질은 누군가 이미 한 삽질이라는걸 다시한번 깨닳은 좋은(?) 시간이였다.
이걸로 나중에 내가 맡고있는 서비스에 대한 웹 자동 테스트 툴도 만들어 볼 생각이다.</div><div class=post-footer><a href=/2018/02/01/linux-selenium/>Read More</a><div class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/linux/>linux</a>,&nbsp;<a href=/tags/python/>python</a>,&nbsp;<a href=/tags/selenium/>selenium</a>,&nbsp;<a href=/tags/chromedriver/>chromedriver</a>,&nbsp;<a href=/tags/archives-2018/>archives-2018</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><div class=featured-image-preview><a href=/2018/01/25/apache-access-log-to-es/><img class=lazyload src=/svg/loading.min.svg data-src=/images/apache-access-log-to-es/model_1.png data-srcset="/images/apache-access-log-to-es/model_1.png, /images/apache-access-log-to-es/model_1.png 1.5x, /images/apache-access-log-to-es/model_1.png 2x" data-sizes=auto alt=/images/apache-access-log-to-es/model_1.png title=/images/apache-access-log-to-es/model_1.png></a></div><h1 class=single-title itemprop="name headline"><a href=/2018/01/25/apache-access-log-to-es/>아파치 엑세스 로그를 엘라스틱서치에 인덱싱 해보자.</a></h1><div class=post-meta><span class=post-author><a href=https://taetaetae.github.io/resume title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw"></i>태태태</a></span>&nbsp;<span class=post-publish>published on <time datetime=2018-01-25>2018-01-25</time></span>&nbsp;<span class=post-category>included in <a href=/categories/tech/><i class="far fa-folder fa-fw"></i>Tech</a></span></div><div class=content>apache access log 를 분석하고 싶은 상황이 생겼다. 아니 그보다 apache access에 대해서 실시간으로 보고싶었고, log를 검색 & 데이터를 가공하여 유의미한 분석결과를 만들어 보고 싶었다. 그에 생각한것이 (역시) ElasticStack.처음에 생각한 방안은 아래 그림처럼 단순했다. 처음 생각한 단순한 구조" 처음 생각한 단순한 구조
하지만, 내 단순한(?) 예상은 역시 빗나갔고 logstash에서는 다음과 같은 에러를 내뱉었다.
retrying individual bulk actions that failed or were rejected by the previous bulk request
request가 많아짐에 따라 elasticsearch가 버벅거리더니 logstash에서 대량작업은 거부하겠다며 인덱싱을 멈췄다. 고민고민하다 elasticsearch에 인덱싱할때 부하가 많이 걸리는 상황에서 중간에 버퍼를 둔 경험이 있어서 facebook그룹에 문의를 해봤다. https://www.facebook.com/groups/elasticsearch.kr/?multi_permalinks=1566735266745641 역시 나보다 한참을 앞서가시는 분들은 이미 에러가 뭔지 알고 있으셨고, 중간에 버퍼를 두고 하니 잘된다는 의견이 있어 나도 따라해봤다. 물론 답변중에 나온 redis가 아닌 기존에도 비슷한 구조에서 사용하고 있던 kafka를 적용. 아, 그전에 현재구성은 Elasticsearch 노드가 총 3대로 클러스터 구조로 되어있는데 노드를 추가로 늘리며 스케일 아웃을 해보기전에 할수있는 마지막 방법이다 생각하고 중간에 kafka를 둬서 부하를 줄여보고 싶었다. (언제부턴가 마치 여러개의 톱니바퀴가 맞물려 돌아가는듯한 시스템 설계를 하는게 재밌었다.) 아래 그림처럼 말이다.
그나마 좀더 생각한 구조" 그나마 좀더 생각한 구조 그랬더니 거짓말 처럼 에러하나 없이 잘 인덱싱이 될수 있었다. logstash가 양쪽에 있는게 약간 걸리긴 하지만, 처음에 생각한 구조보다는 에러가 안나니 다행이라 생각한다.
이 구조를 적용하면서 얻은 Insight가 있기에, 각 항목별로 적어 보고자 한다. ( 이것만 적어놓기엔 너무 없어보여서.. )
access log 를 어떻게 분석하여 인덱싱 할것인가? apache 2.x를 사용하고 별도의 로그 포맷을 정하지 않으면 아래와 같은 access log가 찍힌다. 123.1.1.1 - - [25/Jan/2018:21:55:35 +0900] "GET /api/test?param=12341234 HTTP/1.1" 200 48 1144 "http://www.naver.com/" "Mozilla/5.0 (iPhone; CPU iPhone OS 11_1_2 like Mac OS X) AppleWebKit/604.3.5 (KHTML, like Gecko) Mobile/15B202 NAVER(inapp; blog; 100; 4.0.44)" 그럼 이 로그를 아무 포맷팅 없이 로깅을 하면 그냥 한줄의 텍스트가 인덱싱이 된다. 하지만 이렇게 되면 elasticsearch 데이터를 다시 재가공하거나 별도의 작업이 필요할수도 있으니 중간에 있는 logstash에게 일을 시켜 좀더 nice 한 방법으로 인덱싱을 해보자. 바로 logstash 의 filter 기능이다. 그중 Grok filter 라는게 있는데 패턴을 적용하여 row data 를 필터링하는 기능이다. 조금 찾아보니 너무 고맙게도 아파치 필터 예제가 있어 수정하여 적용할수 있었다. http://grokconstructor.appspot.com/do/match?example=2 그래서 적용한 필터설정은 다음과 같다.
filter { grok { match => { message => "%{IP:clientIp} (?:-|) (?:-|) \[%{HTTPDATE:timestamp}\] \"(?:%{WORD:httpMethod} %{URIPATH:uri}%{GREEDYDATA}(?: HTTP/%{NUMBER})?|-)\" %{NUMBER:responseCode} (?:-|%{NUMBER})" } } } 이렇게 하고 elasticsearch 에 인덱싱을 하면 키바나에서 다음과 같이 볼수 있다. 키바나에 내가 원하는 구조대로 이쁘게 들어가 있는 access log" 키바나에 내가 원하는 구조대로 이쁘게 들어가 있는 access log
각 필드가 아닌 한줄로 인덱싱이 되어버린다. Elasticsearch 에 인덱싱이 되긴 하는데 로그 한줄이 통째로 들어가 버린다. message라는 이름으로&mldr; 알고보니 현재 구조는 logstash가 kafka 앞 뒤에 있다보니 producer logstash 와 consumer logstash 의 codec이 맞아야 제대로 인덱싱이 될수 있었다. 먼저 access log에서 kafka 로 produce 하는 logstash 에서는 output 할때 codec 을 맞춰주고
output { kafka { bootstrap_servers => "123.1.2.3:9092,123.1.2.4:9092" topic_id => "apache-log" codec => json{} } } kafka 에서 consume 하는 logstash 에서는 input 에서 codec 을 맞춰준다.
input { kafka { bootstrap_servers => "123.1.2.3:9092,123.1.2.4:9092" topic_id => "apache-log" codec => json{} } } 그렇게 되면 codec이 맞아 각 필드로 이쁘게 인덱싱을 할수 있게 되었다.
필요없는 uri는 제외하고 인덱싱할수 있을까? /으로는 uri 라던지 /server-status같이 알고있지만 인덱싱은 하기 싫은 경우는 간단하게 아래처럼 if문으로 제외시킬수 있었다.</div><div class=post-footer><a href=/2018/01/25/apache-access-log-to-es/>Read More</a><div class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/elasticsearch/>elasticsearch</a>,&nbsp;<a href=/tags/logstash/>logstash</a>,&nbsp;<a href=/tags/kafka/>kafka</a>,&nbsp;<a href=/tags/access-log/>access log</a>,&nbsp;<a href=/tags/archives-2018/>archives-2018</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><h1 class=single-title itemprop="name headline"><a href=/2018/01/08/python-2-to-3/>파이썬 버전 업그레이드 (2.6 > 3.6)</a></h1><div class=post-meta><span class=post-author><a href=https://taetaetae.github.io/resume title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw"></i>태태태</a></span>&nbsp;<span class=post-publish>published on <time datetime=2018-01-08>2018-01-08</time></span>&nbsp;<span class=post-category>included in <a href=/categories/tech/><i class="far fa-folder fa-fw"></i>Tech</a></span></div><div class=content>파이썬 2.x 에서는 depreate 된 모듈도 많고 3.x에서만 지원되는 버전들이 많아지면서 실컷 개발을 해도 파이썬 버전때문에 다시 짜야하는 상황이 생긴다. 파이썬 버전업을 하고싶어 구글링을 해보면 이렇다할 정리된 문서가 잘 안나온다. (영어로된 포스트는 많이 있긴 하나, 필자의 환경과는 맞지 않는 &mldr;)그래서 이것저것 삽질을 한 결과 파이썬 버전을 올릴수 있었고, 이를 포스팅 해보고자 한다.
그러보고니 2018년 첫 포스팅이네&mldr; 올해는 정말 적어도 한달에 1~2개는 올릴수 있는 내가 되기를&mldr;
환경 CentOS 6.9 기본으로 python 2.6 이 설치되어 있는것을 확인할수 있다. (환경마다 다를수 있음.) $ python -V Python 2.6 설치순서 필요한 유틸리티를 설치한다. $ sudo yum update $ sudo yum install yum-utils $ sudo yum groupinstall development yum 저장소에서는 최신 파이썬 릴리즈를 제공하지 않으므로 RPM 패키를 제공하는 IUM 이라는 추가 저장소를 설치 $ sudo yum install -y https://repo.ius.io/ius-release-el7.rpm 파이썬 3.6 버전을 설치 $ sudo yum install python36u pip 등 패키지 관련 모듈도 함께 설치 sudo yum install python36u-pip sudo yum install python36u-devel 여기까지 하면 기존 파이썬 2.6과 새로 설치된 파이썬 3.6 이 설치되어있다. $ ll /usr/bin/python* -rwxr-xr-x 1 root root 9997450 Jan 2 16:02 python lrwxrwxrwx 1 root root 6 Jan 1 06:02 python2 -> python -rwxr-xr-x 1 root root 9032 Aug 19 2016 python2.6 -rwxr-xr-x 1 root root 1418 Aug 19 2016 python2.6-config -rwxr-xr-x 2 root root 6808 Oct 12 08:19 python3.6 lrwxrwxrwx 1 root root 26 Jan 2 20:48 python3.6-config -> /usr/bin/python3.6m-config -rwxr-xr-x 2 root root 6808 Oct 12 08:19 python3.6m -rwxr-xr-x 1 root root 173 Oct 12 08:19 python3.6m-config -rwxr-xr-x 1 root root 3339 Oct 12 08:16 python3.6m-x86_64-config lrwxrwxrwx 1 root root 16 Apr 25 2017 python-config -> python2.6-config 환경변수를 설정해준다. $ sudo mv python python_backup $ sudo ln -s python3.6 python 확인 $ python -V Python 3.6.3 pip 를 이용한 모듈 설치 pip란 Python Package Index 의 약자로 공식홈페이지는 다음과 같다. ( https://pypi.python.org/pypi/pip ) 설치할 모듈을 다음과 같이 설치해주면 된다. ex : requests 모듈인 경우 $ sudo python3.6 -m pip install requests</div><div class=post-footer><a href=/2018/01/08/python-2-to-3/>Read More</a><div class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/python/>python</a>,&nbsp;<a href=/tags/archives-2018/>archives-2018</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><div class=featured-image-preview><a href=/2017/12/14/elastic-on-tour/><img class=lazyload src=/svg/loading.min.svg data-src=/images/elastic-on-tour/ElasticStackWorkshop.jpg data-srcset="/images/elastic-on-tour/ElasticStackWorkshop.jpg, /images/elastic-on-tour/ElasticStackWorkshop.jpg 1.5x, /images/elastic-on-tour/ElasticStackWorkshop.jpg 2x" data-sizes=auto alt=/images/elastic-on-tour/ElasticStackWorkshop.jpg title=/images/elastic-on-tour/ElasticStackWorkshop.jpg></a></div><h1 class=single-title itemprop="name headline"><a href=/2017/12/14/elastic-on-tour/>Elastic{ON}Tour</a></h1><div class=post-meta><span class=post-author><a href=https://taetaetae.github.io/resume title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw"></i>태태태</a></span>&nbsp;<span class=post-publish>published on <time datetime=2017-12-14>2017-12-14</time></span>&nbsp;<span class=post-category>included in <a href=/categories/review/><i class="far fa-folder fa-fw"></i>review</a></span></div><div class=content>작년에 팀을 옮기면서 로깅에 대해서 관심을 갖기 시작 하였고 찾아보다 ElasticStack 이 적합하다고 판단, 팀 내에서 나홀로 삽질해가며 지금의 로그 모니터링 시스템을 구축하였다. 그에 ElasticStack 에 관심을 갖던 찰나 지난 화요일(12월 12일)에 있었던 Elastic On Tour에 참석을 하였고 다양한 기술적 인사이트를 얻을수 있었는데 그 감동(?)을 잃기 싫어 정리해보고자 한다.
Registration + Partner Showcase 코엑스 인터컨티넨탈 호텔에서 진행되었다. 역시 외국계 기업이여서 그런지 행사 규모가 어마어마 했다. 이정표를 따라 지하로 가서 등록을 하고, ElasticStack 을 이용해서 서비스를 하고 있는 파트너사들의 부스를 기웃거리며 ElasticStack의 저력(?)을 다시한번 실감을 할수 있었다. 특히 Elatic 본사에서 나온듯한 외국인들이 Q&A 같은걸 해줬는데 답변을 해주는 외국인도 대단해 보였는데 질문을 하는 한국사람(?)들이 더 대단하게 보였다. 과연 난 저렇게 아무렇지 않고 프로페셔널(?)하게 질문을 할수 있을까? Registration + Partner Showcase" Registration + Partner Showcase
Track 1 : Partner Sessions Track 1 과 2로 나뉘였는데 2는 Elastic Stack 을 경험하지 못해봤거나 소개하는 자리같아서 Track 1를 듣기로 하였다. 내가 도입을 할때만 해도 관련 자료가 잘 없었고, 정말 특이 케이스가 아닌 이상엔 잘 사용하지 않겠구나 하는 느낌이였는데 발표하시는 분들을 보고서는 생각이 180도 바뀌었다. 너무 활용들을 잘 하며 서비스를 하고 있었고 단순하게 검색엔진이 아닌 상황에 맞는 커스터 마이징이나 다른 기술 스택을 함께 사용함으로써 시너지 효과를 내고 있었다.
Microsoft OpenSource 에 안좋은 이미지가 있으나 오래전부터 투자를 많이 해왔다고 설명을 하며 Azure라는 서비스에서 Elastic Stack 을 어떤식으로 활용하는지 발표를 하였다. 상당히 심플하고 처음 접하는 사람도 클릭 몇번으로 ES Cluster를 구성할수 있다는게 장점이였으나, 유료 + 커스터마이징 제한 이 아쉬웠다. S-Core : 에스코어 경험에 기반한 Elastic 활용법 EZFarm (외모 비하는 아니지만)농부 처럼 생기신 분이 나와서 기술에 대해 말씀하시는게 신기한 발표였다. 간단히 말하면 돼지가 물 먹는 량 등 농업/축산업의 데이터를 ES에 담고 머신러닝을 통하여 효율화 하는 방안 이였던것 같다. MEGAZONE 파트너 부스에서 티셔츠를 준(?) 곳이였는데 Elastic Cloud Seoul 을 발표하였다. (드디어 한국에도 이런 서비스가!) OpenBase 키바나 플러그인을 직접 개발하고 커스텀 UI의 사례를 보여주었다. 키바나 소스중에 엑셀 다운로드가 한글로 안되어 고쳐본것 말곤 플러그인을 개발할 생각은 없었는데 정말 개발자 스러운 발표였다. DIREA 결제 관련 장애추적 및 예측 시스템을 발표하였다. 마침 내가 하고있는 서비스와 비슷하고, 내가 구현해보려고 했던 부분과 거의 일맥상통한 부분이 있어서 소름이였다. Track 1 : Partner Sessions" Track 1 : Partner Sessions Opening Keynote 앞서 어떤 발표에서 ElasticSearch가 탄생하게된 계기가 어떤 분이 요리사가 되려는 아내를 위해 조리법을 더 빨리 검색할수 있는 엔진을 만들었다고 하는데 그 어떤분이 내눈앞에 나타나 발표를 하셨다. 현 Elastic CEO 이신 Shay Banon 이였다. (어색한 동시 통역으로 이해하였지만) 그분이 강조하신 Elastic 회사 정신인 &ldquo;간단한건 간단하게 만들어야 하며 쉬워야 한다.&rdquo; 가 연설중에 가장 인상적이였고, 통역하신 아주머님(?)때문이였는지 전달하시는 의도를 정확히 파악하긴 어려웠으나 일단 CEO를 포함한 전체 회사 분위기가 젊어보인다는걸 느낄수 있었다.
Shay Banon key note" Shay Banon key note Break (식사시간) 이런 세미나? 컨퍼런스? 를 많이 다녀본건 아니지만 역대급으로 좋았던 점심식사였다. ;) 사실 혼자와서 밥을 어떻게 해결하나 했는데 우르르르 호텔 직원분들이 각 자리에 도시락을 대령(?)해주셔서 맛있게 먹을수 있었다. 참 사람이 간사한게, 아침에 졸린눈 비벼가며 지옥철 고생을 뚫고 와서 힘들었지만 밥을 먹으면서 아침의 그 고생은 눈녹듯 사라졌다.
호텔 도시락!!" 호텔 도시락!! Deep Dive (Elasticsearch, Ingest, Kibana, Machine Learning) 각 스택(?)에 대해서 변화된 부분, 그리고 활용가능성과 최근 출시한 6.</div><div class=post-footer><a href=/2017/12/14/elastic-on-tour/>Read More</a><div class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/elasticsearch/>elasticsearch</a>,&nbsp;<a href=/tags/archives-2017/>archives-2017</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><div class=featured-image-preview><a href=/2017/11/02/what-is-kafka/><img class=lazyload src=/svg/loading.min.svg data-src=/images/what-is-kafka/kafka.png data-srcset="/images/what-is-kafka/kafka.png, /images/what-is-kafka/kafka.png 1.5x, /images/what-is-kafka/kafka.png 2x" data-sizes=auto alt=/images/what-is-kafka/kafka.png title=/images/what-is-kafka/kafka.png></a></div><h1 class=single-title itemprop="name headline"><a href=/2017/11/02/what-is-kafka/>What is Kafka?</a></h1><div class=post-meta><span class=post-author><a href=https://taetaetae.github.io/resume title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw"></i>태태태</a></span>&nbsp;<span class=post-publish>published on <time datetime=2017-11-02>2017-11-02</time></span>&nbsp;<span class=post-category>included in <a href=/categories/tech/><i class="far fa-folder fa-fw"></i>Tech</a></span></div><div class=content>필자가 맡고있는 서비스에 Elastic Stack 을 도입하면서 중간에 버퍼가 필요하여 Message-Queue 시스템들을 알아보던 중 Kafka 에 대해 알아보고, 정리를 해보게 된다.
기본설명 및 기존 메세징 시스템과 다른점 메세징 큐의 일종 말 그대로 분산형 스트리밍 플랫폼, LinkedIn에서 여러 구직 + 채용 정보들을 한곳에서 처리(발행/구독)할수 있는 플랫폼으로 개발이 시작 대용량의 실시간 로그 처리에 특화되어 설계된 메시징 시스템, 기존 범용 메시징 시스템대비 TPS가 매우 우수 메시지를 기본적으로 메모리에 저장하는 기존 메시징 시스템과는 달리 메시지를 파일 시스템에 저장 → 카프카 재시작으로 인한 메세지 유실 우려 감소 기존의 메시징 시스템에서는 broker가 consumer에게 메시지를 push해 주는 방식인데 반해, Kafka는 consumer가 broker로부터 직접 메시지를 가지고 가는 pull 방식으로 동작하기 때문에 consumer는 자신의 처리능력만큼의 메시지만 broker로부터 가져오기 때문에 최적의 성능을 낼 수 있다. 카프카 주요 개념 producer : 메세지 생산(발행)자. consumer : 메세지 소비자 consumer group : consumer 들끼리 메세지를 나눠서 가져간다.offset 을 공유하여 중복으로 가져가지 않는다. broker : 카프카 서버를 가리킴 zookeeper : 카프카 서버 (+클러스터) 상태를 관리하고 cluster : 브로커들의 묶음 topic : 메세지 종류 partitions : topic 이 나눠지는 단위 Log : 1개의 메세지 offset : 파티션 내에서 각 메시지가 가지는 unique id 카프카는 어떤식으로 돌아가는가 zookeeper 가 kafka 의 상태와 클러스터 관리를 해준다.
정해진 topic 에 producer 가 메세지를 발행해놓으면 consumer 가 필요할때 해당 메세지를 가져간다. (여기서 카프카로 발행된 메세지들은 consumer가 메세지를 소비한다고 해서 없어지는게 아니라 카프카 설정 log.retention.hours(default : 168[7일])에 의해 삭제된다.)
partition 개수와 consumer group 개념 하얀색(consumer-01) : 파티션 개수가 4개인데 비해 컨슈머가 3개, 이렇게 되면 어느 컨슈머가 두개의 파티션을 담당해야하는 상황이 생긴다. 주황색(consumer-02) : 파티션 개수가 4개인데 비해 컨슈머가 5개, 이렇게 되면 하나의 노는(?) 컨슈머가 생기는 상황이 생긴다. 가장 적절한 개수는 정해지지 않았지만 통상 컨슈머그룹의 컨슈머 개수와 파티션 개수를 동일하게 가져가곤 한다. 참고 url http://kafka.apache.org/ http://www.popit.kr/author/peter5236/ http://jinhokwon.tistory.com/168 http://programist.tistory.com/entry/Apache-Kafka-클러스터링-구축-및-테스트 https://www.elastic.co/kr/blog/just-enough-kafka-for-the-elastic-stack-part1 https://www.slideshare.net/springloops/apache-kafka-intro20150313springloops-46067669</div><div class=post-footer><a href=/2017/11/02/what-is-kafka/>Read More</a><div class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/kafka/>kafka</a>,&nbsp;<a href=/tags/archives-2017/>archives-2017</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><div class=featured-image-preview><a href=/2017/10/16/deview-2017-review/><img class=lazyload src=/svg/loading.min.svg data-src=/images/deview-2017-review/deview_main.jpg data-srcset="/images/deview-2017-review/deview_main.jpg, /images/deview-2017-review/deview_main.jpg 1.5x, /images/deview-2017-review/deview_main.jpg 2x" data-sizes=auto alt=/images/deview-2017-review/deview_main.jpg title=/images/deview-2017-review/deview_main.jpg></a></div><h1 class=single-title itemprop="name headline"><a href=/2017/10/16/deview-2017-review/>Deview-2017 Day1 리뷰</a></h1><div class=post-meta><span class=post-author><a href=https://taetaetae.github.io/resume title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw"></i>태태태</a></span>&nbsp;<span class=post-publish>published on <time datetime=2017-10-16>2017-10-16</time></span>&nbsp;<span class=post-category>included in <a href=/categories/blog/><i class="far fa-folder fa-fw"></i>blog</a></span></div><div class=content>벌써 10번째 Naver에서 주최하는 Deview. 올해도 어김없이 참석을 하게 되었고, 이번엔 보고 듣고 느꼈던 부분들을 조금이라도 간직하고 싶은 마음에 바로 블로깅을 하려고 한다. (오랜만에 블로깅이긴 하지만&mldr;)항상 Deview에 올때마다 느끼는 부분인데 이번참석이 3번째 되는듯 하다 세상은 좁고 능력자는 많으며 내가 한번쯤 본것들은 이미 지나간 기술들이라는것, 더불어 단상위에 올라가 발표하는 사람들도 예전엔 나와 똑같이 발표를 듣는 일반 사람이였다는것. 이번에도 많은 생각을 하게 되었다. 구구절절 개인적으로 느낀점을 적는것에 앞서 강한 기억이 남았던 몇몇 세션들에 대해서 간략하게 리뷰를 먼저 하는게 맞는 순서같다.
책 읽어주는 딥러닝 ( 김태훈 / 데브시스터즈 ) 슬라이드 자료
네이버에서 유인나의 목소리로 책을 읽어주는것을 보고 흥미를 얻어 개발하기 시작했다고 한다. 음성합성은 데이터가 많아야 머신러닝이나 딥러닝 기술을 접목시키는데 도움이 되는데 박근혜 전 대통령, 문재인 대통령, 손석희 아나운서의 영상에서 데이터를 추출하여 문장별로 텍스트-음성을 맞추고(pair) 머신러닝 + 딥러닝 기술을 이용해서 만들수 있었다고 한다. 추후 누구나 사용할 수 있도록 파이썬 모듈로 제공한다고 하니, 감사할 따름이다. 사실 머신러닝에 관심만있었지 이렇다할 공부나 직접 구현은 단한번도 안해보고 해당 세션을 들어보니 그냥 우와 신기하다정도였는데. 이번기회에 작은것부터 하나씩 시작하면서 요즈음 핫한(?) 트랜드를 따라가는 것도 괜찮은 방법같아 보인다. (앗, 우선 파이썬부터&mldr;)
그런 REST API로 괜찮은가 ( 이응준 / 비바리퍼블리카 ) 슬라이드 자료
발표자분을 어디서 많이 봤다 했더니만 예전에 우리 회사 사람이였다. 수업도 들어봤고, 같이 알고리즘 스터디도 했고(한번 나갔지만&mldr;). 발표 첫 부분에 자신이 10년전에 데뷰 staff 를 시작했는데 10년을 다 못채우고 퇴사를 했다고 ㅎㅎ.. 아무튼 개인적으로 나름 반가운 분이라 더 관심갖고 듣게 되었다. REST 가 무엇인가?에 대한 발표다. 결론부터 말하자면 아래 3가지중 하나를 사용하면 될것이라고 한다.
REST API 를 구현하고 REST API라고 부른다. REST API 구현을 포기하고 HTTP API 라고 부른다. REST API 가 아니지만 REST API 라고 부른다. (현재 대부분의 API들의 상태) REST API를 구성하는 스타일중 눈여겨 볼만한 부분은 크게 두가지가 있다고 한다. (uniform interface)
self-descriptive messages : 메시지는 스스로 설명이 되어야 한다. hypermedia as the engine of application state (HATEOAS) : 전이(상태의 이동)가 될수있는 정보가 있어야 한다. 정리를 해보면 REST API로 만들려면 제대로 알고 만들어라 라는 메시지가 강한 발표내용같다. 나도 이제까지는 그냥 json 으로 내려준다는 것, GETㆍPOST 등 HTTP Method 사용하는 것으로만 알고있었는데 개인적으로는 발표자분이 말씀하신 두가지 내용은 지키는게 맞다고 생각한다. 즉, 정말 REST 하게 만들꺼면 정확한 사용법을 알고 만드는게 좋아보인다.
동네 커피샵도 사이렌오더를 쓸 수 있을까? ( 허형, 나동진 / 삼성전자[Lunch class] ) 슬라이드 자료
오늘 발표중에 가장 들어보고 싶었던 세션. 예전부터 사이렌오더가 어떤식으로 동작하는지 + 우리회사 커피숍도 사내 앱을 활용해서 만들어 볼순 없을지(아이디어) 이런저런 생각이 많았었는데 딱! 원하던 발표가 있어 듣게 되었다. 삼성전자 소속이신 분들이 따로 그룹을 만들어 진행하면서 만난 부분들을 발표해주셨는데 신기한 기술들이 많아 듣는 내내 흥미진진 했다.
PWA(Progressive Web App) : PWA 로 모바일 청첩장을 만들었다고 한다. (결혼식 전날입니다. 오늘 결혼합니다. 이벤트[추첨]를 진행합니다. 등등..) Physical Web(Beacon), NFC &mldr; Browser Fingerprint (Device 구분) Push Nofification Web Payment 결국 정리를 해보면 동네 커피샵에서 사이렌 오더를 사용하기위해 이러저러한 기술들을 시도해봤다~인데. 각 기술들에 있어 현실적인 상황에 한계점이 있고, 그래서 결국 처음에 이야기 된 동네 커피샵에서 사이렌 오더를 사용에 대한 결과물이 없어서 아쉬웠다. 엄청 기대했는데 말이다. 하지만 PWA를 이용해서 모바일 청접장을 만든 부분은 정말 찬사를 보내주고 싶은 아이디어 같다.나도 나중에 해야지~ 예전 &ldquo;날씨"라는 웹서비스를 만들면서 웹이라는 환경에서 기상속보나 갑작스러운 눈/비 알림을 단순히 화면에 뿌려주는것이 아니라 사용자 기기에 노티(푸시)해줄수는 없을까하며 잠깐 본 기술이 PWA 였는데 난 프로토타이핑만 해본 수준이지만 이분들은 실제로 본업과는 별개로 구현을 해보는 노력을 했다는것에 내 자신이 부끄러워 진다.</div><div class=post-footer><a href=/2017/10/16/deview-2017-review/>Read More</a><div class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/deview/>deview</a>,&nbsp;<a href=/tags/archives-2017/>archives-2017</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><div class=featured-image-preview><a href=/2017/08/28/apache-keep-alive/><img class=lazyload src=/svg/loading.min.svg data-src=/images/apache-keep-alive/keepalive_on_off.png data-srcset="/images/apache-keep-alive/keepalive_on_off.png, /images/apache-keep-alive/keepalive_on_off.png 1.5x, /images/apache-keep-alive/keepalive_on_off.png 2x" data-sizes=auto alt=/images/apache-keep-alive/keepalive_on_off.png title=/images/apache-keep-alive/keepalive_on_off.png></a></div><h1 class=single-title itemprop="name headline"><a href=/2017/08/28/apache-keep-alive/>Apache keepAlive</a></h1><div class=post-meta><span class=post-author><a href=https://taetaetae.github.io/resume title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw"></i>태태태</a></span>&nbsp;<span class=post-publish>published on <time datetime=2017-08-28>2017-08-28</time></span>&nbsp;<span class=post-category>included in <a href=/categories/tech/><i class="far fa-folder fa-fw"></i>Tech</a></span></div><div class=content><p>서버를 운영하다보면 간혹 문제가 발생하곤 한다. 이를테면 메모리가 다른이유없이 올라간다거나, 사용자 입장에서 응답속도가 간헐적으로 느린다거나. 그럴때마다 선배개발자분들께서 가장먼저 입에 오르내리는 단어. <code>keepAlive</code>.</p></div><div class=post-footer><a href=/2017/08/28/apache-keep-alive/>Read More</a><div class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/apache/>apache</a>,&nbsp;<a href=/tags/keepalive/>keepAlive</a>,&nbsp;<a href=/tags/archives-2017/>archives-2017</a></div></div></article><ul class=pagination><li class=page-item><span class=page-link><a href=/>1</a></span></li><li class=page-item><span class=page-link aria-hidden=true>&mldr;</span></li><li class=page-item><span class=page-link><a href=/page/6/>6</a></span></li><li class=page-item><span class=page-link><a href=/page/7/>7</a></span></li><li class="page-item active"><span class=page-link><a href=/page/8/>8</a></span></li><li class=page-item><span class=page-link><a href=/page/9/>9</a></span></li><li class=page-item><span class=page-link><a href=/page/10/>10</a></span></li><li class=page-item><span class=page-link><a href=/page/11/>11</a></span></li></ul></div></div></main><footer class=footer><div class=footer-container><div class=footer-line>Powered by <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.74.3">Hugo</a> | Theme - <a href=https://github.com/dillonzq/LoveIt target=_blank rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i>LoveIt</a></div><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2016 - 2024</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=https://taetaetae.github.io/resume target=_blank>태태태</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw"></i></a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw"></i></a></div><link rel=stylesheet href=/lib/lightgallery/lightgallery.min.css><script type=text/javascript src=/lib/smooth-scroll/smooth-scroll.min.js></script><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/lightgallery/lightgallery.min.js></script><script type=text/javascript src=/lib/lightgallery/lg-thumbnail.min.js></script><script type=text/javascript src=/lib/lightgallery/lg-zoom.min.js></script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/sharer/sharer.min.js></script><script type=text/javascript src=/lib/typeit/typeit.min.js></script><script type=text/javascript>window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":500},"data":{"id-1":"Software Engineer Crazy for Growth"},"lightGallery":{"actualSize":false,"exThumbImage":"data-thumbnail","hideBarsDelay":2000,"selector":".lightgallery","speed":400,"thumbContHeight":80,"thumbWidth":80,"thumbnail":true},"typeit":{"cursorChar":"|","cursorSpeed":500,"data":{"id-1":["id-1"]},"duration":-1,"speed":100}};</script><script type=text/javascript src=/js/theme.min.js></script><script type=text/javascript>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js',new Date());gtag('config','UA-86432198-1',{'anonymize_ip':true});</script><script type=text/javascript src="https://www.googletagmanager.com/gtag/js?id=UA-86432198-1" async></script></body></html>