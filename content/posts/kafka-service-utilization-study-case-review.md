---
title: "KAFKA 서비스 활용 스터디 사례 밋업 후기"
date: 2023-02-19T23:39:22+09:00
categories:
  - review
tags: 
  - kafka
  - archives-2023
featuredImage: /images/kafka-meetup-2019/kafka.jpg
images :
  - /images/kafka-meetup-2019/kafka.jpg
---

　필자는 오프라인에서 진행하는 밋업이나 콘퍼런스 가는 것을 좋아한다. 발표하는 내용을 전부다 이해해서 듣고 온다는 건 거짓말이겠지만 간혹 들었던 내용을 팀 내에 적용해 본다거나 몰랐던 내용에 대해 알게 되는 경우가 많았다. 특히, 질문을 꼭 하는 편인데 질문을 하려고 하면 좀 더 집중해서 듣게 되거나 질문한 세션의 내용은 꽤 오랫동안 기억에 남게 되니 개발자 행사에 참석하면 꼭 질문을 하자는 게 필자 자신과의 약속 중에 하나이기도 하다.

　한동안 코로나로 모든 개발자 행사가 온라인으로 진행하는 등 오프라인 행사는 눈을 씻고 찾기란 하늘에 별 따기였다. 오프라인 행사에 참여하면 나름의 개발력(?)을 얻을 수 있었는데 오프라인 행사 자체를 하지 않아 괜히 기운이 빠지던 요 몇 년이었지 않았나 싶다. 그러다 [페이스북 KAFKA 한국 사용자 모임](https://www.facebook.com/groups/kafka.kru)에서 공지가 올라왔고 [세션](https://devocean.sk.com/events/view.do?id=155)들을 보아하니 하나도 알아듣지 못할(?) 엄청나게 고차원의 내용이 아닌 그럭저럭 이해할 만한 내용으로 준비되어 있었고, 무엇보다 회사와 가까워서 설레는 마음으로 신청을 하였다. 오래전에도 한번 밋업에 [참석한 적](/2019/03/31/kafka-meetup-2019/)이 있었는데 나름 진행도 매끄러웠고 좋았던 기억들뿐이라 한 치의 망설임 없이 신청하게 되었다.

{{< image src="/images/kafka-service-utilization-study-case-review/ezic_bridge.png" caption="신입사원때 자주 오가던 다리..." width="100%" >}}

　오전 근무만 하고 판교 테크노벨리에 있는 유명한 다리인 `이직의 다리`를 건너 SKT/SKP 판교 사옥 1층으로 걸어간다. 판교에 올 일이 잘 없는 게 올 때마다 느끼는 건 정말 IT 회사가 많다는 것. 뭔가 이직을 하려고 마음을 먹지 않아도 괜히 마음이 바운스 거리는 건 기분탓 일까 싶다.

## 밋업의 분위기

　이런 행사에 가면 맨 앞에 자리를 잡곤 해서 처음엔 몰랐는데 행사 진행 중간에 보니 사회자분 이야기로는 약 90여 명 정도가 왔다고 했다. 오프라인 행사라 그런 건지, 판교 직장인분들의 접근성이 좋아서인지, 아님 정말 KAFKA의 인기(?)가 좋아서 인지는 모르겠지만 예상보다 꽤 많이 와서 조금 놀랬다. 입구에 커피와 쿠키가 제공되었고 개발자 노트북에 덕지덕지 붙일 수 있는 개발자 스티커도 받을 수 있었다. 

　이번에는 [데보션(Devocen)](https://devocean.sk.com/) 이라는 곳에서 후원을 받아 진행한다고 했다. 처음에 데보션이 뭐 하는 곳인지에 대한 간략한 소개와 나중에 추첨을 하기 위해 앱을 설치하라는 귀여운 홍보도 있었다. SK 내/외부 우수 인재가 모여 전문 기술 지식/정보를 등록/축적 하고 공유 교류를 하며 전파 및 확산에 집중을 한다고 한다. 테크 세미나가 월 1회 있다고 하니 종종 들어와 봐야 겠다는 생각을 해본다. 

　카프카 모임을 이끄시는 고승범 님도 오셨다. 예전 밋업에서도 뵙긴 했지만 최근에 카프카 관련 책도 새롭게 내시고 그룹도 운영 중이신 분이다. 나는 과연 저러한 열정이 있었나? 있을 수 있나? 라는 생각을 잠시 해본다. 

## 발표 요약

　하나부터 열까지 받아쓰기 수준으로 적진 못했지만 그래도 메모장에 남아있는 기록들을 정리 및 요약해 본다. 오랜만의 오프라인 행사라 들떠서인지 잘못된 기록이 있을 수 있음을 알린다 ^^;

### Kafka MirrorMaker로 카오스 엔지니어링 맛보기 / 황한희 님
- Kafka MirrorMaker? - 카프카 클러스터를 대상으로 데이터를 mirroring 하는 기능 (토픽 데이터 동기화)
- 활용방식 : fan-out, aggregation, active-active, acitve-passive
- 카오스 엔지니어링 : 운영환경에서도 갑작스러운 장애를 견딜 수 있는 시스템을 구축하기 위해 시스템을 실험하는 분야, 장애를 미리 경험
  - https://en.wikipedia.org/wiki/Chaos_engineering
- Chaos Monkey
  - 넷플릭스 개발팀의 운영 원칙으로부터 시작해 현재는 가장 대표적인 카오스 테스팅 도구
  - 마치 무기를 든 원숭이를 데이터 센터에 풀어 놓은것 같다는 의미에서 출발
- Pumba
  - 컨테이너 환경에서 제공되는 카오스 엔지니어링 도구
  - 영화 라이온킹에 등장하는 멧돼지인 품바의 멍청하고 산만하다는 특징에서 영감을 받음
  - 비교적 단순한 테스팅을 할 때 유용한 도구
- 카오스 엔지니어링 파이프라인
  - 안정화 정의 : 기술적인 이슈나 아닌 비즈니스 관점의 지표를 안정된 상태의 지표로 설정
  - 이벤트 선정 : 발생 가능성이 있는 이벤트 선정
  - 실행 : 카오스 엔지니어링 수행 , 실제로 이벤트를 발생시켜보고 가설을 시험
  - 분석

　이번에도 어김없이 질문을 했다. 아무래도 실 서비스의 접근을 해야 할 텐데 부담은 없을지, 성능에 영향은 없을지가 가장 궁금했다. 답변으로는 pub/sub 이 하나 더 발생하는 것이기 때문에 성능에 큰 영향은 없을 것이라고 답변을 받았다. 과연 그럴까? 라는 생각을 잠깐 해보고 팀 내에서 카오스 엔지니어링을 도입하게 되면 개발 환경부터 테스트 해봐야지 하는 생각을 해봤다. 

　카오스 엔지니어링 이라는 그럴듯한 이름으로 테스트를 하진 않았지만 실 서비스 도입 전에 별도의 환경(real/stage)에서 테스트를 하고는 있다. 그렇지만 지금 이야기 하고 있는 건 실 서비스의 모든 데이터를 동일하게 받고(dump) 정의된 테스트 파이프라인에 따라 계획적으로 진행하는 걸 이야기 하는 것 같았다. 민방위 훈련(?) 같은 장애를 발생시키는 테스트를 하지만 과연 제대로 하고 있나? 싶은 생각도 들었고 나중에 카오스 엔지니어링을 도입해 보는 것도 좋겠다는 생각도 들었다.

### 취준생이 경험한 커뮤니티의 가치 / 김경민
　이번 세션은 어떠한 기술을 전파한다기 보다 세션 제목 그대로 취업 준비생이 경험한 커뮤니티의 가치에 대한 느낌을 전달해 주셨다. (호랑이 담배 필적 생각도 나고 ㅎㅎ) 처음엔 단순하게 유튜브 알고리즘을 배워보자(만들어보자?)로 시작했는데 커뮤니티에 참여하며 끊임없이 공부할 수 있는 기회를 얻었다는 것에 너무 신난 표정으로 발표하시는 게 인상적이었다. 신기한 게 많다고 하셨는데 그 느낌.. RG..RG.. 더군다나 이끌어 줄 사람이 있어서 좋았다고 하셨다. 역시 커뮤니티는 개발자에게 꼭 필요한 도구이자 없어서는 안될 존재인 건 확실한 것 같다.

### KakfaAdminclienet API를 이용한 Kakfa Managing 서비스 개발 / 이상헌, 이진환
- kafkaAdminClient? : Kafka Object의 정보를 조회하고 매니징하는데 사용할수 있는 class이고, 이를 통해 kafka cluster의 내부 옵션을 설정 가능
- 왜 사용하는가? kafka cluster의 내부 옵션 설정/변경 관련된 내용을 자동화
- code dependency : kakfa-clients

　야후에서 만든 [kafka-manager](https://github.com/yahoo/CMAK)와 무엇이 다른가..라고 질문을 하고 싶었지만 뭔가 상태에 따라 매니징을 자동화하는 툴을 만들 때 보다 괜찮은 방법이 될 수도 있겠구나 생각이 들었다.

### pub/sub기능을 활용하여 로컬 캐시 동기화하기 / 조한서
- 로컬캐시의 문제점을 해결하기 (동기화)
- 캐시(Cache)란?
  - 데이터를 미리 저장해서 빠른 응답을 기대
  - hit : 저장한 데이터를 요청했을때
  - 더 많은 요청과 더 빠르게 시스템을 운영할수 있다.
- Local Cache vs Global(remote) Cache
  - local : Speed(속도) ⬆, Consistency(일관성) ⬇/ 읽기요청이 쓰기 요청보다 많을때 적합
  - global : Speed ⬇, Consistency ⬆
- 문제점 : 데이터가 업데이트 되는 순간 인스턴스마다 다른 캐시 정보를 가지고 있고 조회시 업데이트가 되었지만 이전 데이터를 조회할 가능성이 있다.
  - 해결방법
      - 인스턴스마다 각각 업데이트
      - pub/sub 기능 활용 ← 소개 방안
      - expire time을 짧게
- 데이터 변경시 kafka로 pub하고 다른 인스턴스 에서는 sub하여 반영
    - set만 kafka 로 pub/sub으로 발행
    - get은 로컬캐시를 이용
    - 로컬캐시의 동기화가 목적 (리모트 캐시는 x)

　다른 분께서 질문도 하셨고 필자도 의문을 가진 '어느 상황에서 사용되는가, 문제점은 없는가'라는 질문에는 역시나 `No Silver Bullet`. 상황에 따라 좋은 대안이 될 수도 안될 수도 있다고 정리가 되었다. 캐시 관련 되서는 차라리 expire time을 적당히 짧게 가져가는 게 리소스 측면에서 효율적이지 않을까 생각을 해봤다.

## 마무리
  {{< image src="/images/kafka-service-utilization-study-case-review/kakfa_meetup.png" caption="찍힌 사진이 무슨 대감처럼 나왔네... + get 한 카프카 책!" width="100%" >}}

　사실, 필자도 사람인지라 경품을 받고 싶어 굳이 빈 백팩을 메고 갔지만 빙빙 돌아가는 룰렛은 다른 분의 이름을 호명하기 바빴고, 그렇지만 질문을 해서 책을 받기도 했지만 무엇보다 너무 오랜만에 오프라인 개발자 행사에 와보니 뭔가 닫혀있던 생각들이 환기되는 기분도 받았고 녹아 없어져 버린 열정도 다시 찾을 수 있겠다는 희망도 얻어 가는 것 같았다. 다음에 또 와야징.


> 그나저나, 너...무 오랜만의 포스팅이라 부끄럽기도 하고 그렇다. TMI이지만 요즘엔 블로그 보단 [커리어리](https://careerly.co.kr/profiles/105233)라는 서비스에서 활동(?)을 하다 보니 개발자에게 그렇게도 중요하다고 이야기 하는 블로그를 등한시 한 것 같은데, 이 포스팅을 시작으로 다시 블로그를 종종 써보도록 노력 해야겠다;;