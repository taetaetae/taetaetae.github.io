<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><meta http-equiv=x-ua-compatible content="IE=edge, chrome=1"><title>시계열 데이터를 분석하여 미래 예측 하기(Anomaly Detection) - 👨‍💻꿈꾸는 태태태의 공간</title><meta name=Description content><meta property="og:title" content="시계열 데이터를 분석하여 미래 예측 하기(Anomaly Detection)"><meta property="og:description" content="급변하는 날씨를 예측하려면 어떠한 정보가 있어야 할까? 또는 마트를 운영하는 담당자인 경우 매장 운영시간을 정해야 한다면 어떠한 기준으로? 뜨거운 감자인 비트코인 시장에서 수익을 얻으려면 어떤 정보들이 있어야 물리지(?) 않을수 있을까?
위 질문에 공통된 정답은 예전 기록들인것 같다. 날씨예측은 기상청에서 과거 기록들을 보고 비가 올지 말지를 결정하고 ( 과거 날씨 서비스를 담당해봤지만 단순히 과거 기록들로 예측한다는건 불가능에 가깝긴 하다. ) 매장 운영시간은 예전에 손님들이 언제왔는지에 대한 데이터를 보고. 비트코인이나 주식은 차트를 보고 어느정도는 상승장일지 하락장일지 추측이 가능하다고 한다. ( 물론 호재/악재에 따라 흔들리지만..ㅠㅠ..?? ) 이처럼 시간의 흐름에 따라 만들어진 데이터를 분석하는것을 시계열 데이터 분석이라 부르고 있다. 필자가 운영하는 서비스에서 시계열 데이터 분석을 통해 장애를 사전에 방지하는 사례를 공유 해보고자 한다.
상황파악부터 손자병법에는 지피지기 백전불태 라는 말이 있다. 그만큼 현 상황을 잘 알아야 대응을 잘할수 있다는것. 필자가 운영하는 서비스는 PG(Payment Gateway) 서비스로 쇼핑몰같은 온/오프라인 사업자와 실제 카드사와의 중간 역활을 해주고 있다. 이를테면 사용자가 생수를 10,000원에 XX카드로 구매해줘 라고 요청이 오면 그 정보를 다시 형식에 맞춰 카드사로 전달하여 사용자가 물건을 구매할수 있도록 해준다.
PG서비스 : 쇼핑몰과 카드사의 중간에서 릴레이 해주는 역활이라 보면된다.&#34; PG서비스 : 쇼핑몰과 카드사의 중간에서 릴레이 해주는 역활이라 보면된다.  요구사항 및 과거 데이터 분석 서비스를 운영해보니 감지하기 어려운 상황들이 있었다.
 연동하는 쇼핑몰에서 문제가 발생하거나 네트워크 문제가 발생할경우 즉, 트래픽이 평소보다 적게 들어올 경우 정상적인 에러(e.g. 잔액부족) 가 갑자기 많이 발생할 경우  이를 분석하기위해 기존의 트래픽/데이터를 분석해봐야 했다.
결제건수 Kibana Visualize, 기영이 패턴&#34; 결제건수 Kibana Visualize, 기영이 패턴  위 그래프는 결제데이터 카운트 인데 어느정도 패턴을 찾을수 있다.
에러건수 Kibana Visualize, 악어 패턴..(무리수..)&#34; 에러건수 Kibana Visualize, 악어 패턴..(무리수..)  위 그래프는 에러카운트 인데 일정한 패턴 속에서 어느 지점에서는 튀는것을 확인할수 있다. (빨간색 영역) 그렇다면 어떤 방법으로 장애상황보다 앞서서 감지를 할수 있을까? ( 장애 : 어떠한 내/외부 요인으로 인해 정상적인 서비스가 되지 않는 상태 )
장애발생 전에 먼저 찾아보자! 가장 간단하게는 기존 데이터를 보고 수동으로 설정하는 방법이 있을수 있다. 예로들어 자정 즈음에는 결제량이 가장 많기때문에 약 xx건으로 설정해두고, 새벽에는 결제량이 가장 적기 때문에 약 yy건으로 설정해둔 후 에러 건수나 결제건수에 대해 실시간으로 검사를 해가면서 설정한 값보다 벗어날 경우 알림을 주는 방법이다. 하지만 아무리 과거 데이터를 완벽하게 분석했다 할지라도 24시간 모든 시점에서 예측은 벗어날 수밖에 없다. (예로들어 쇼핑 이벤트를 갑작스럽게 하게되면 결제량은 예측하지 못할정도로 늘어날테고&mldr;) 또한 설정한 예측값을 벗어날 경우 수동으로 다시 예측값을 조정해줘야 하는데, 이럴꺼면 24시간 종합 상황실에서 사람이 직접 눈으로 보는것 보다 못할것 같다. (인력 리소스가 충분하다면 뭐&mldr; 그렇게 해도 된다.)
지난 데이터와 비교하기 일주일 기준으로 지난 일주일과의 데이터를 비교해보는 방법또한 있다. 간단하게 설명하면 이번주 월요일 10시의 데이터와 지난주 월요일 10시의 데이터의 차이를 비교해보는 방법이다. 키바나에서 클릭 몇번만으로 시각화를 도와주는 Visualize 기능을 통해 지난 일주일과 이번주를 비교해보면 아래 그래프처럼 표현이 가능하다.
일주일 전 데이터와 단순 비교&#34; 일주일 전 데이터와 단순 비교  이 경우도 지난주 상황과 이번주 상황이 다른 경우에는 원하는 비교 항목 외에 다른 요인이 추가되기 때문에 원하는 비교를 할수가 없고 위에서 수동으로 설정하는 방법과 별반 다를바 없을것으로 생각된다.
조금더 우아하게! (언제부턴가 우아하단 말을 좋아하는것 같다..) 개발자는 문제에 대해서 언제나 분석을 토대로 접근을 하는것을 목표로 해야한다. 언제부턴가 Hot한 머신러닝을 도입해 보고 싶었으나 아직 그런 실력이 되질 못하고&mldr; 폭풍 구글링을 통해 알게된 Facebook에서 만든 Prophet이라는 모듈을 활용해보고자 한다. https://opensource.fb.com/#artificial 이곳에 가보면 여러 Artificial Intelligence 관련된 오픈소스들중에 Prophet 모듈을 찾을수 있다."><meta property="og:type" content="article"><meta property="og:url" content="https://taetaetae.github.io/2018/05/31/anomaly-detection/"><meta property="og:image" content="https://taetaetae.github.io/images/anomaly-detection/kiyoung_chart.png"><meta property="article:published_time" content="2018-05-31T17:03:41+00:00"><meta property="article:modified_time" content="2018-05-31T17:03:41+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://taetaetae.github.io/images/anomaly-detection/kiyoung_chart.png"><meta name=twitter:title content="시계열 데이터를 분석하여 미래 예측 하기(Anomaly Detection)"><meta name=twitter:description content="급변하는 날씨를 예측하려면 어떠한 정보가 있어야 할까? 또는 마트를 운영하는 담당자인 경우 매장 운영시간을 정해야 한다면 어떠한 기준으로? 뜨거운 감자인 비트코인 시장에서 수익을 얻으려면 어떤 정보들이 있어야 물리지(?) 않을수 있을까?
위 질문에 공통된 정답은 예전 기록들인것 같다. 날씨예측은 기상청에서 과거 기록들을 보고 비가 올지 말지를 결정하고 ( 과거 날씨 서비스를 담당해봤지만 단순히 과거 기록들로 예측한다는건 불가능에 가깝긴 하다. ) 매장 운영시간은 예전에 손님들이 언제왔는지에 대한 데이터를 보고. 비트코인이나 주식은 차트를 보고 어느정도는 상승장일지 하락장일지 추측이 가능하다고 한다. ( 물론 호재/악재에 따라 흔들리지만..ㅠㅠ..?? ) 이처럼 시간의 흐름에 따라 만들어진 데이터를 분석하는것을 시계열 데이터 분석이라 부르고 있다. 필자가 운영하는 서비스에서 시계열 데이터 분석을 통해 장애를 사전에 방지하는 사례를 공유 해보고자 한다.
상황파악부터 손자병법에는 지피지기 백전불태 라는 말이 있다. 그만큼 현 상황을 잘 알아야 대응을 잘할수 있다는것. 필자가 운영하는 서비스는 PG(Payment Gateway) 서비스로 쇼핑몰같은 온/오프라인 사업자와 실제 카드사와의 중간 역활을 해주고 있다. 이를테면 사용자가 생수를 10,000원에 XX카드로 구매해줘 라고 요청이 오면 그 정보를 다시 형식에 맞춰 카드사로 전달하여 사용자가 물건을 구매할수 있도록 해준다.
PG서비스 : 쇼핑몰과 카드사의 중간에서 릴레이 해주는 역활이라 보면된다.&#34; PG서비스 : 쇼핑몰과 카드사의 중간에서 릴레이 해주는 역활이라 보면된다.  요구사항 및 과거 데이터 분석 서비스를 운영해보니 감지하기 어려운 상황들이 있었다.
 연동하는 쇼핑몰에서 문제가 발생하거나 네트워크 문제가 발생할경우 즉, 트래픽이 평소보다 적게 들어올 경우 정상적인 에러(e.g. 잔액부족) 가 갑자기 많이 발생할 경우  이를 분석하기위해 기존의 트래픽/데이터를 분석해봐야 했다.
결제건수 Kibana Visualize, 기영이 패턴&#34; 결제건수 Kibana Visualize, 기영이 패턴  위 그래프는 결제데이터 카운트 인데 어느정도 패턴을 찾을수 있다.
에러건수 Kibana Visualize, 악어 패턴..(무리수..)&#34; 에러건수 Kibana Visualize, 악어 패턴..(무리수..)  위 그래프는 에러카운트 인데 일정한 패턴 속에서 어느 지점에서는 튀는것을 확인할수 있다. (빨간색 영역) 그렇다면 어떤 방법으로 장애상황보다 앞서서 감지를 할수 있을까? ( 장애 : 어떠한 내/외부 요인으로 인해 정상적인 서비스가 되지 않는 상태 )
장애발생 전에 먼저 찾아보자! 가장 간단하게는 기존 데이터를 보고 수동으로 설정하는 방법이 있을수 있다. 예로들어 자정 즈음에는 결제량이 가장 많기때문에 약 xx건으로 설정해두고, 새벽에는 결제량이 가장 적기 때문에 약 yy건으로 설정해둔 후 에러 건수나 결제건수에 대해 실시간으로 검사를 해가면서 설정한 값보다 벗어날 경우 알림을 주는 방법이다. 하지만 아무리 과거 데이터를 완벽하게 분석했다 할지라도 24시간 모든 시점에서 예측은 벗어날 수밖에 없다. (예로들어 쇼핑 이벤트를 갑작스럽게 하게되면 결제량은 예측하지 못할정도로 늘어날테고&mldr;) 또한 설정한 예측값을 벗어날 경우 수동으로 다시 예측값을 조정해줘야 하는데, 이럴꺼면 24시간 종합 상황실에서 사람이 직접 눈으로 보는것 보다 못할것 같다. (인력 리소스가 충분하다면 뭐&mldr; 그렇게 해도 된다.)
지난 데이터와 비교하기 일주일 기준으로 지난 일주일과의 데이터를 비교해보는 방법또한 있다. 간단하게 설명하면 이번주 월요일 10시의 데이터와 지난주 월요일 10시의 데이터의 차이를 비교해보는 방법이다. 키바나에서 클릭 몇번만으로 시각화를 도와주는 Visualize 기능을 통해 지난 일주일과 이번주를 비교해보면 아래 그래프처럼 표현이 가능하다.
일주일 전 데이터와 단순 비교&#34; 일주일 전 데이터와 단순 비교  이 경우도 지난주 상황과 이번주 상황이 다른 경우에는 원하는 비교 항목 외에 다른 요인이 추가되기 때문에 원하는 비교를 할수가 없고 위에서 수동으로 설정하는 방법과 별반 다를바 없을것으로 생각된다.
조금더 우아하게! (언제부턴가 우아하단 말을 좋아하는것 같다..) 개발자는 문제에 대해서 언제나 분석을 토대로 접근을 하는것을 목표로 해야한다. 언제부턴가 Hot한 머신러닝을 도입해 보고 싶었으나 아직 그런 실력이 되질 못하고&mldr; 폭풍 구글링을 통해 알게된 Facebook에서 만든 Prophet이라는 모듈을 활용해보고자 한다. https://opensource.fb.com/#artificial 이곳에 가보면 여러 Artificial Intelligence 관련된 오픈소스들중에 Prophet 모듈을 찾을수 있다."><meta name=application-name content="👨‍💻꿈꾸는 태태태의 공간"><meta name=apple-mobile-web-app-title content="👨‍💻꿈꾸는 태태태의 공간"><meta name=naver-site-verification content="2d1cdbb963ba178aa7cbf58500afc668cae1e645"><meta name=google-site-verification content="vvFCdv0-GuQhEWG8vtNJfA7YSY2HYQ1hpHh9P-a6Pv8"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://taetaetae.github.io/2018/05/31/anomaly-detection/><link rel=prev href=https://taetaetae.github.io/2018/04/29/apache-408-response-code/><link rel=next href=https://taetaetae.github.io/2018/06/27/apache-vs-nginx/><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"시계열 데이터를 분석하여 미래 예측 하기(Anomaly Detection)","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/taetaetae.github.io\/2018\/05\/31\/anomaly-detection\/"},"genre":"posts","keywords":"python, anomaly detection, elasticsearch, prophet, facebook, archives-2018","wordcount":1089,"url":"https:\/\/taetaetae.github.io\/2018\/05\/31\/anomaly-detection\/","datePublished":"2018-05-31T17:03:41+00:00","dateModified":"2018-05-31T17:03:41+00:00","publisher":{"@type":"Organization","name":"태태태"},"author":{"@type":"Person","name":"태태태"},"description":""}</script></head><body header-desktop=auto header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem('theme')?localStorage.getItem('theme')==='dark':('auto'==='auto'?window.matchMedia('(prefers-color-scheme: dark)').matches:'auto'==='dark'))&&document.body.setAttribute('theme','dark');</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="👨‍💻꿈꾸는 태태태의 공간">👨‍💻꿈꾸는 태태태의 공간</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>Posts </a><a class=menu-item href=/tags/>Tags </a><a class=menu-item href=/categories/>Categories </a><span class="menu-item delimiter"></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="👨‍💻꿈꾸는 태태태의 공간">👨‍💻꿈꾸는 태태태의 공간</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><a class=menu-item href=/posts/>Posts</a><a class=menu-item href=/tags/>Tags</a><a class=menu-item href=/categories/>Categories</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div><script async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script><ins class=adsbygoogle style=display:inline-block;width:260px;height:600px data-ad-client=ca-pub-5788330009690816 data-ad-slot=2248955907></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({});</script></div><article class="page single"><h1 class="single-title animated flipInX">시계열 데이터를 분석하여 미래 예측 하기(Anomaly Detection)</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://taetaetae.github.io/resume title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw"></i>태태태</a></span>&nbsp;<span class=post-category>included in <a href=/categories/tech/><i class="far fa-folder fa-fw"></i>Tech</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2018-05-31>2018-05-31</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;1089 words&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;6 minutes&nbsp;</div></div><div class=featured-image><img class=lazyload src=/svg/loading.min.svg data-src=/images/anomaly-detection/kiyoung_chart.png data-srcset="/images/anomaly-detection/kiyoung_chart.png, /images/anomaly-detection/kiyoung_chart.png 1.5x, /images/anomaly-detection/kiyoung_chart.png 2x" data-sizes=auto alt=/images/anomaly-detection/kiyoung_chart.png title=/images/anomaly-detection/kiyoung_chart.png></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#상황파악부터>상황파악부터</a></li><li><a href=#요구사항-및-과거-데이터-분석>요구사항 및 과거 데이터 분석</a></li><li><a href=#장애발생-전에-먼저-찾아보자>장애발생 전에 먼저 찾아보자!</a></li><li><a href=#지난-데이터와-비교하기>지난 데이터와 비교하기</a></li><li><a href=#조금더-우아하게-언제부턴가-우아하단-말을-좋아하는것-같다>조금더 우아하게! <code>(언제부턴가 우아하단 말을 좋아하는것 같다..)</code></a></li><li><a href=#마치며>마치며</a></li></ul></nav></div></div><div class=content id=content><p>급변하는 날씨를 예측하려면 어떠한 정보가 있어야 할까?
또는 마트를 운영하는 담당자인 경우 매장 운영시간을 정해야 한다면 어떠한 기준으로?
뜨거운 감자인 비트코인 시장에서 수익을 얻으려면 어떤 정보들이 있어야 물리지(?) 않을수 있을까?</p><p>위 질문에 공통된 정답은 <code>예전 기록들</code>인것 같다. 날씨예측은 기상청에서 과거 기록들을 보고 비가 올지 말지를 결정하고 ( 과거 날씨 서비스를 담당해봤지만 단순히 과거 기록들로 예측한다는건 불가능에 가깝긴 하다. ) 매장 운영시간은 예전에 손님들이 언제왔는지에 대한 데이터를 보고. 비트코인이나 주식은 차트를 보고 어느정도는 상승장일지 하락장일지 추측이 가능하다고 한다. ( 물론 호재/악재에 따라 흔들리지만..ㅠㅠ..?? )
이처럼 시간의 흐름에 따라 만들어진 데이터를 분석하는것을 <code>시계열 데이터 분석</code>이라 부르고 있다. 필자가 운영하는 서비스에서 시계열 데이터 분석을 통해 장애를 사전에 방지하는 사례를 공유 해보고자 한다.</p><h2 id=상황파악부터>상황파악부터</h2><p>손자병법에는 지피지기 백전불태 라는 말이 있다. 그만큼 현 상황을 잘 알아야 대응을 잘할수 있다는것. 필자가 운영하는 서비스는 PG(Payment Gateway) 서비스로 쇼핑몰같은 온/오프라인 사업자와 실제 카드사와의 중간 역활을 해주고 있다. 이를테면 사용자가 <code>생수를 10,000원에 XX카드로 구매해줘</code> 라고 요청이 오면 그 정보를 다시 형식에 맞춰 카드사로 전달하여 사용자가 물건을 구매할수 있도록 해준다.</p><figure><a class=lightgallery href=/images/anomaly-detection/pg.png title=/images/anomaly-detection/pg.png data-thumbnail=/images/anomaly-detection/pg.png data-sub-html="<h2>PG서비스 : 쇼핑몰과 카드사의 중간에서 릴레이 해주는 역활이라 보면된다.</h2>"><img class=lazyload src=/svg/loading.min.svg data-src=/images/anomaly-detection/pg.png data-srcset="/images/anomaly-detection/pg.png, /images/anomaly-detection/pg.png 1.5x, /images/anomaly-detection/pg.png 2x" data-sizes=auto alt=/images/anomaly-detection/pg.png></a><figcaption class=image-caption>PG서비스 : 쇼핑몰과 카드사의 중간에서 릴레이 해주는 역활이라 보면된다.</figcaption></figure><h2 id=요구사항-및-과거-데이터-분석>요구사항 및 과거 데이터 분석</h2><p>서비스를 운영해보니 감지하기 어려운 상황들이 있었다.</p><ul><li>연동하는 쇼핑몰에서 문제가 발생하거나 네트워크 문제가 발생할경우 즉, 트래픽이 평소보다 적게 들어올 경우</li><li>정상적인 에러(e.g. 잔액부족) 가 갑자기 많이 발생할 경우</li></ul><p>이를 분석하기위해 기존의 트래픽/데이터를 분석해봐야 했다.</p><figure><a class=lightgallery href=/images/anomaly-detection/trade_count.png title=/images/anomaly-detection/trade_count.png data-thumbnail=/images/anomaly-detection/trade_count.png data-sub-html="<h2>결제건수 Kibana Visualize, 기영이 패턴</h2>"><img class=lazyload src=/svg/loading.min.svg data-src=/images/anomaly-detection/trade_count.png data-srcset="/images/anomaly-detection/trade_count.png, /images/anomaly-detection/trade_count.png 1.5x, /images/anomaly-detection/trade_count.png 2x" data-sizes=auto alt=/images/anomaly-detection/trade_count.png></a><figcaption class=image-caption>결제건수 Kibana Visualize, 기영이 패턴</figcaption></figure><p>위 그래프는 결제데이터 카운트 인데 어느정도 패턴을 찾을수 있다.</p><figure><a class=lightgallery href=/images/anomaly-detection/error_count.png title=/images/anomaly-detection/error_count.png data-thumbnail=/images/anomaly-detection/error_count.png data-sub-html="<h2>에러건수 Kibana Visualize, 악어 패턴..(무리수..)</h2>"><img class=lazyload src=/svg/loading.min.svg data-src=/images/anomaly-detection/error_count.png data-srcset="/images/anomaly-detection/error_count.png, /images/anomaly-detection/error_count.png 1.5x, /images/anomaly-detection/error_count.png 2x" data-sizes=auto alt=/images/anomaly-detection/error_count.png></a><figcaption class=image-caption>에러건수 Kibana Visualize, 악어 패턴..(무리수..)</figcaption></figure><p>위 그래프는 에러카운트 인데 일정한 패턴 속에서 어느 지점에서는 튀는것을 확인할수 있다. (빨간색 영역) 그렇다면 어떤 방법으로 장애상황보다 앞서서 감지를 할수 있을까? ( 장애 : 어떠한 내/외부 요인으로 인해 정상적인 서비스가 되지 않는 상태 )</p><h2 id=장애발생-전에-먼저-찾아보자>장애발생 전에 먼저 찾아보자!</h2><p>가장 간단하게는 기존 데이터를 보고 수동으로 설정하는 방법이 있을수 있다. 예로들어 자정 즈음에는 결제량이 가장 많기때문에 약 xx건으로 설정해두고, 새벽에는 결제량이 가장 적기 때문에 약 yy건으로 설정해둔 후 에러 건수나 결제건수에 대해 실시간으로 검사를 해가면서 설정한 값보다 벗어날 경우 알림을 주는 방법이다.
하지만 아무리 과거 데이터를 완벽하게 분석했다 할지라도 24시간 모든 시점에서 예측은 벗어날 수밖에 없다. (예로들어 쇼핑 이벤트를 갑작스럽게 하게되면 결제량은 예측하지 못할정도로 늘어날테고&mldr;) 또한 설정한 예측값을 벗어날 경우 수동으로 다시 예측값을 조정해줘야 하는데, 이럴꺼면 24시간 종합 상황실에서 사람이 직접 눈으로 보는것 보다 못할것 같다. (인력 리소스가 충분하다면 뭐&mldr; 그렇게 해도 된다.)</p><h2 id=지난-데이터와-비교하기>지난 데이터와 비교하기</h2><p>일주일 기준으로 지난 일주일과의 데이터를 비교해보는 방법또한 있다. 간단하게 설명하면 이번주 월요일 10시의 데이터와 지난주 월요일 10시의 데이터의 차이를 비교해보는 방법이다. 키바나에서 클릭 몇번만으로 시각화를 도와주는 Visualize 기능을 통해 지난 일주일과 이번주를 비교해보면 아래 그래프처럼 표현이 가능하다.</p><figure><a class=lightgallery href=/images/anomaly-detection/visualize.png title=/images/anomaly-detection/visualize.png data-thumbnail=/images/anomaly-detection/visualize.png data-sub-html="<h2>일주일 전 데이터와 단순 비교</h2>"><img class=lazyload src=/svg/loading.min.svg data-src=/images/anomaly-detection/visualize.png data-srcset="/images/anomaly-detection/visualize.png, /images/anomaly-detection/visualize.png 1.5x, /images/anomaly-detection/visualize.png 2x" data-sizes=auto alt=/images/anomaly-detection/visualize.png></a><figcaption class=image-caption>일주일 전 데이터와 단순 비교</figcaption></figure><p>이 경우도 지난주 상황과 이번주 상황이 다른 경우에는 원하는 비교 항목 외에 다른 요인이 추가되기 때문에 원하는 비교를 할수가 없고 위에서 수동으로 설정하는 방법과 별반 다를바 없을것으로 생각된다.</p><h2 id=조금더-우아하게-언제부턴가-우아하단-말을-좋아하는것-같다>조금더 우아하게! <code>(언제부턴가 우아하단 말을 좋아하는것 같다..)</code></h2><p>개발자는 문제에 대해서 언제나 분석을 토대로 접근을 하는것을 목표로 해야한다. 언제부턴가 Hot한 머신러닝을 도입해 보고 싶었으나 아직 그런 실력이 되질 못하고&mldr; 폭풍 구글링을 통해 알게된 Facebook에서 만든 <a href=https://facebook.github.io/prophet/ target=_blank rel="noopener noreffer">Prophet</a>이라는 모듈을 활용해보고자 한다.
<a href=https://opensource.fb.com/#artificial>https://opensource.fb.com/#artificial</a> 이곳에 가보면 여러 Artificial Intelligence 관련된 오픈소스들중에 Prophet 모듈을 찾을수 있다. 다행히도 <a href=https://namu.wiki/w/BSD%20%EB%9D%BC%EC%9D%B4%EC%84%A0%EC%8A%A4 target=_blank rel="noopener noreffer">BSD License</a>라서 실무에서도 다양하게 활용할수 있을것으로 보인다. 친절하게도 <code>Quick Start</code>을 통해 어떤식으로 예측을 하는지 보여준다. 참고로 Python 과 R 을 지원한다. (python 의 대단함을 다시금 느끼며&mldr;)
구성은 CentOS 7 + python3.6 + jenkins 를 활용한다. (python 경험이 부족하므로 코드가 허접할수도 있으니 양해바란다.)
데이터 분석시 가장 많이 사용된다는 <code>Pandas</code>와 대규모 다차원 배열을 쉽게 처리 할 수 있게 해주는 <code>numpy</code>, 그리고 <code>bprophet</code>를 비롯한 필요한 모듈들을 pip로 설치해준다.</p><div class=highlight><pre class=chroma><code class=language-shell data-lang=shell>pip install pandas
pip install fbprophet
pip install numpy
</code></pre></div><p>필요한 모듈들을 import를 한다.</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=kn>import</span> <span class=nn>matplotlib</span>
<span class=n>matplotlib</span><span class=o>.</span><span class=n>use</span><span class=p>(</span><span class=s1>&#39;Agg&#39;</span><span class=p>)</span> <span class=o>//</span> <span class=n>centos</span> <span class=err>서버</span> <span class=err>환경에서</span> <span class=err>돌릴경우</span> <span class=err>예측결과를</span> <span class=err>그래프로</span> <span class=err>보는</span> <span class=err>과정에서</span> <span class=err>오류가</span> <span class=err>발생한다</span><span class=o>.</span> <span class=err>이를</span> <span class=err>방직하기</span> <span class=err>위해</span> <span class=err>해당</span> <span class=err>코드를</span> <span class=err>적어준다</span><span class=o>.</span>

<span class=kn>import</span> <span class=nn>pandas</span> <span class=kn>as</span> <span class=nn>pd</span>
<span class=kn>import</span> <span class=nn>requests</span><span class=o>,</span> <span class=nn>datetime</span>
<span class=kn>from</span> <span class=nn>fbprophet</span> <span class=kn>import</span> <span class=n>Prophet</span>
</code></pre></div><p>기존에 데이터들은 모두 실시간으로 elasticserach에 인덱싱 중이기 때문에 rest api 를 활용하면 쉽게 데이터를 얻을수가 있다. (RDB로 관리를 했더라면&mldr; 배보다 배꼽이 더 큰 상황이였지 않았을까 하는 생각이 든다.)</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=c1># 현재 시 기준 2주 (24 x 14 시간) 전의 데이터를 가져온다.</span>
<span class=n>day_gap</span> <span class=o>=</span> <span class=mi>14</span>

<span class=n>now_datetime</span> <span class=o>=</span> <span class=n>datetime</span><span class=o>.</span><span class=n>datetime</span><span class=o>.</span><span class=n>now</span><span class=p>()</span>
<span class=n>end_time</span> <span class=o>=</span> <span class=n>datetime</span><span class=o>.</span><span class=n>datetime</span><span class=p>(</span><span class=n>now_datetime</span><span class=o>.</span><span class=n>year</span><span class=p>,</span> <span class=n>now_datetime</span><span class=o>.</span><span class=n>month</span><span class=p>,</span> <span class=n>now_datetime</span><span class=o>.</span><span class=n>day</span><span class=p>,</span> <span class=n>now_datetime</span><span class=o>.</span><span class=n>hour</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span><span class=mi>0</span><span class=p>)</span>
<span class=n>end_time_stamp</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>end_time</span><span class=o>.</span><span class=n>timestamp</span><span class=p>()</span> <span class=o>*</span> <span class=mi>1000</span><span class=p>))</span>
<span class=n>start_time</span> <span class=o>=</span> <span class=n>end_time</span> <span class=o>-</span> <span class=n>datetime</span><span class=o>.</span><span class=n>timedelta</span><span class=p>(</span><span class=n>days</span><span class=o>=</span><span class=n>day_gap</span><span class=p>)</span>
<span class=n>start_time_stamp</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>start_time</span><span class=o>.</span><span class=n>timestamp</span><span class=p>()</span> <span class=o>*</span> <span class=mi>1000</span><span class=p>))</span>

<span class=n>url</span> <span class=o>=</span> <span class=s1>&#39;http://elasticsearch:9200/_msearch&#39;</span>
<span class=n>headers</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s2>&#34;Content-Type&#34;</span> <span class=p>:</span> <span class=s2>&#34;application/x-ndjson&#34;</span>
<span class=p>}</span>
<span class=n>es_data</span> <span class=o>=</span> <span class=s1>&#39;{&#34;index&#34;:[&#34;index_name&#34;]}</span><span class=se>\n</span><span class=s1>{&#34;size&#34;:0,&#34;query&#34;:{&#34;bool&#34;:{&#34;must&#34;:[{&#34;range&#34;:{&#34;log_time&#34;:{&#34;gte&#34;:&#39;</span> <span class=o>+</span> <span class=n>start_time_stamp</span> <span class=o>+</span> <span class=s1>&#39;,&#34;lte&#34;:&#39;</span> <span class=o>+</span> <span class=n>end_time_stamp</span> <span class=o>+</span> <span class=s1>&#39;}}}]}},&#34;aggs&#34;:{&#34;2&#34;:{&#34;date_histogram&#34;:{&#34;field&#34;:&#34;log_time&#34;,&#34;interval&#34;:&#34;1h&#34;, &#34;time_zone&#34;:&#34;Asia/Tokyo&#34;}}}}</span><span class=se>\n</span><span class=s1>&#39;</span>
<span class=n>response_list</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>post</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>url</span><span class=p>,</span> <span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>,</span> <span class=n>data</span><span class=o>=</span><span class=n>es_data</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=s1>&#39;utf-8&#39;</span><span class=p>))</span><span class=o>.</span><span class=n>json</span><span class=p>()[</span><span class=s1>&#39;responses&#39;</span><span class=p>][</span><span class=mi>0</span><span class=p>][</span><span class=s1>&#39;aggregations&#39;</span><span class=p>][</span><span class=s1>&#39;2&#39;</span><span class=p>][</span><span class=s1>&#39;buckets&#39;</span><span class=p>]</span>
<span class=k>print</span><span class=p>(</span><span class=s1>&#39;기준 : &#39;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>start_time</span><span class=p>)</span> <span class=o>+</span> <span class=s1>&#39; ~ &#39;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>end_time</span><span class=p>))</span>

<span class=c1># es 데이터 중 시간값을 형식에 바꾸면서 key-value 형태로 정제한다.</span>
<span class=n>query_result</span> <span class=o>=</span> <span class=p>{}</span>
<span class=k>for</span> <span class=n>data</span> <span class=ow>in</span> <span class=n>response_list</span> <span class=p>:</span>
    <span class=n>query_result</span><span class=p>[</span><span class=n>data</span><span class=p>[</span><span class=s1>&#39;key_as_string&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s1>&#39;T&#39;</span><span class=p>,</span><span class=s1>&#39; &#39;</span><span class=p>)</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s1>&#39;.000+09:00&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>)]</span> <span class=o>=</span> <span class=n>data</span><span class=p>[</span><span class=s1>&#39;doc_count&#39;</span><span class=p>]</span>
</code></pre></div><p>elasticsearch에서 aggregation을 활용하여 데이터를 1시간 단위로 가져올경우 데이터가 없는 경우를 대비해 비어있는 시간에 해당하는 카운트를 0으로 맞춰주기 위하여 loop를 돌며 데이터를 정제해준다. (이 방법보다 더 좋은 방법이 분명 있을것이다&mldr;)</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>anomaly_detection_base_data</span> <span class=o>=</span> <span class=p>{}</span>

<span class=k>for</span> <span class=n>data</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>24</span> <span class=o>*</span> <span class=n>day_gap</span><span class=p>)</span> <span class=p>:</span>
    <span class=n>key_date_time</span> <span class=o>=</span> <span class=n>start_time</span><span class=o>.</span><span class=n>strftime</span><span class=p>(</span><span class=s1>&#39;%Y-%m-</span><span class=si>%d</span><span class=s1> %H:00:00&#39;</span><span class=p>)</span>
    <span class=k>if</span> <span class=n>key_date_time</span> <span class=ow>in</span> <span class=n>query_result</span> <span class=p>:</span>
        <span class=n>anomaly_detection_base_data</span><span class=p>[</span><span class=n>key_date_time</span><span class=p>]</span> <span class=o>=</span> <span class=n>query_result</span><span class=p>[</span><span class=n>key_date_time</span><span class=p>]</span>
    <span class=k>else</span> <span class=p>:</span>
        <span class=n>anomaly_detection_base_data</span><span class=p>[</span><span class=n>key_date_time</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>
    <span class=n>start_time</span> <span class=o>=</span> <span class=n>start_time</span> <span class=o>+</span> <span class=n>datetime</span><span class=o>.</span><span class=n>timedelta</span><span class=p>(</span><span class=n>hours</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</code></pre></div><p>pandas 를 활용하여 데이터를 DataFrame 형식에 맞춰준 다음 <code>시간</code>기준으로 다음 24시간의 데이터를 예측하도록 한다.</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=n>anomaly_detection_base_data</span><span class=o>.</span><span class=n>items</span><span class=p>()),</span> <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;ds&#39;</span><span class=p>,</span> <span class=s1>&#39;y&#39;</span><span class=p>])</span>
<span class=n>m</span> <span class=o>=</span> <span class=n>Prophet</span><span class=p>()</span>
<span class=n>m</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>df</span><span class=p>)</span>
<span class=n>future</span> <span class=o>=</span> <span class=n>m</span><span class=o>.</span><span class=n>make_future_dataframe</span><span class=p>(</span><span class=n>periods</span><span class=o>=</span><span class=mi>24</span> <span class=p>,</span> <span class=n>freq</span><span class=o>=</span><span class=s1>&#39;H&#39;</span><span class=p>)</span>
<span class=n>forecast</span> <span class=o>=</span> <span class=n>m</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>future</span><span class=p>)</span>
</code></pre></div><p>실제 집계한 값과 예측값을 비교하여 알림발생 유무를 결정한다.</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=c1># 현재시간 -1시간 전 실제 집계</span>
<span class=n>check_datetime</span> <span class=o>=</span> <span class=n>now_datetime</span> <span class=o>-</span> <span class=n>datetime</span><span class=o>.</span><span class=n>timedelta</span><span class=p>(</span><span class=n>hours</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
<span class=n>check_datetime</span> <span class=o>=</span> <span class=n>check_datetime</span><span class=o>.</span><span class=n>strftime</span><span class=p>(</span><span class=s1>&#39;%Y-%m-</span><span class=si>%d</span><span class=s1> %H:00:00&#39;</span><span class=p>)</span>
<span class=n>check_datetime_count</span> <span class=o>=</span> <span class=n>query_result</span><span class=p>[</span><span class=n>check_datetime</span><span class=p>]</span>
<span class=k>print</span><span class=p>(</span><span class=s1>&#39;실제 집계수 : &#39;</span> <span class=o>+</span> <span class=n>check_datetime</span> <span class=o>+</span> <span class=s1>&#39; → &#39;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>check_datetime_count</span><span class=p>))</span>

<span class=c1># 예측 최대치</span>
<span class=n>forecast_max_count</span> <span class=o>=</span> <span class=n>forecast</span><span class=p>[</span><span class=n>forecast</span><span class=o>.</span><span class=n>ds</span> <span class=o>==</span> <span class=n>check_datetime</span><span class=p>][</span><span class=s1>&#39;yhat_upper&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>values</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
<span class=k>print</span><span class=p>(</span><span class=s1>&#39;예측 최대치 : &#39;</span> <span class=o>+</span> <span class=n>check_datetime</span>  <span class=o>+</span> <span class=s1>&#39; → &#39;</span> <span class=o>+</span>  <span class=nb>str</span><span class=p>(</span><span class=n>forecast_max_count</span><span class=p>))</span> 
</code></pre></div><p>여기서는 에러 카운트가 평소와는 다르게 발생할 경우에 알림을 발송을 하려 하기때문에 아래처럼 구성을 해준다.</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=k>if</span> <span class=n>check_datetime_count</span> <span class=o>&gt;</span> <span class=n>forecast_max_count</span> <span class=p>:</span>
  <span class=c1># 예측한 결과를 이미지로 저장후 알림에 포함시켜준다.</span>
  <span class=n>forecast_graph</span> <span class=o>=</span> <span class=n>m</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>forecast</span><span class=p>,</span> <span class=n>plot_cap</span><span class=o>=</span><span class=bp>False</span><span class=p>,</span> <span class=n>xlabel</span><span class=o>=</span><span class=s1>&#39;time&#39;</span><span class=p>,</span> <span class=n>ylabel</span><span class=o>=</span><span class=s1>&#39;count&#39;</span><span class=p>);</span>
  <span class=n>file_name</span> <span class=o>=</span> <span class=s1>&#39;forecast_graph.png&#39;</span>
  <span class=n>forecast_graph</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=n>file_name</span><span class=p>)</span>
</code></pre></div><p>이런 python script를 jenkins 를 활용하여 1시간에 한번씩 실행될수있도록 구성해 두고 문제가 발생할때는 아래처럼 메일로 알림을 받는다.</p><figure><a class=lightgallery href=/images/anomaly-detection/forecast_graph.png title=/images/anomaly-detection/forecast_graph.png data-thumbnail=/images/anomaly-detection/forecast_graph.png data-sub-html="<h2>예측결과</h2>"><img class=lazyload src=/svg/loading.min.svg data-src=/images/anomaly-detection/forecast_graph.png data-srcset="/images/anomaly-detection/forecast_graph.png, /images/anomaly-detection/forecast_graph.png 1.5x, /images/anomaly-detection/forecast_graph.png 2x" data-sizes=auto alt=/images/anomaly-detection/forecast_graph.png></a><figcaption class=image-caption>예측결과</figcaption></figure><p>위 그래프를 분석하면 다음과 같다.</p><ul><li>검정색 점 : 실제 데이터</li><li>파란 실선 : 트랜드 그래프</li><li>하늘색 음영 : 예측한 최대/최소치의 영역
빨간색으로 표시한 점 두개를 보면 예측을 벗어난것을 확인할수 있고 실제로 저 시간대에 내부적 이슈로 인해 에러가 많이 발생한 경우이다. (장애 발생 시점)</li></ul><p>이런식으로 구성을 해두면 앞서 수동으로 최대/최소 수치를 정해두고 이탈했는지에 대해서 모니터링 하는것보다 훨씬더 우아하게 모니터링을 할수있다.
물론 해당 모듈이 완벽하다는 소리는 아니다. 필자도 해당 모듈을 사용하다보니 어떤 경우에서는 예측수치와 실제 데이터가 비슷한 경우가 있어 알람을 받은 경우도 있다. 예전 포스팅에서도 이야기 했듯 정답은 없는것 같다. 상황에 맞춰서 지속적으로 커스터마이징을 해야하는게 개발자의 숙명 아닐까 싶다.</p><h2 id=마치며>마치며</h2><p>사실 이렇게 <code>시계열 데이터</code>라는 단어나 <code>Prophet</code>같은 오픈소스를 검색할수 있었던건 작년 <a href=https://taetaetae.github.io/2017/12/14/elastic-on-tour/ target=_blank rel="noopener noreffer">Elastic{ON}Tour 에서 봤던 Elastic X-pack의 머신러닝 기능</a> 때문이다. 그때 받은 충격(?)이 아직까지 있는건지 이렇게 오픈소스로 비슷하게나마 구현할수 있었던 원동력이 된것 같다. 기회가 되면 X-pack을 구매해서 운영하는 서비스에 머신러닝을 활용해서 이러한 시계열 데이터에 대해 분석해보고싶다.</p></div><center><style>.bmc-button img{width:27px!important;margin-bottom:1px!important;box-shadow:none!important;border:none!important;vertical-align:middle!important}.bmc-button{line-height:29px!important;height:30px!important;text-decoration:none!important;display:inline-flex!important;color:#000!important;background-color:#fd0!important;border-radius:3px!important;border:1px solid transparent!important;padding:1px 9px!important;font-size:22px!important;letter-spacing:.6px!important;box-shadow:0 1px 2px rgba(190,190,190,.5)!important;-webkit-box-shadow:0 1px 2px 2px rgba(190,190,190,.5)!important;margin:0 auto!important;font-family:cookie,cursive!important;-webkit-box-sizing:border-box!important;box-sizing:border-box!important;-o-transition:.3s all linear!important;-webkit-transition:.3s all linear!important;-moz-transition:.3s all linear!important;-ms-transition:.3s all linear!important;transition:.3s all linear!important}.bmc-button:hover,.bmc-button:active,.bmc-button:focus{-webkit-box-shadow:0 1px 2px 2px rgba(190,190,190,.5)!important;text-decoration:none!important;box-shadow:0 1px 2px 2px rgba(190,190,190,.5)!important;opacity:.85!important;color:#000!important}</style><link href="https://fonts.googleapis.com/css?family=Cookie" rel=stylesheet><center><br><a class=bmc-button target=_blank href=https://www.buymeacoffee.com/taetaetae><img src=https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg alt="Buy me a coffee"><span style=margin-left:5px>Buy me a coffee</span></a>
<a href=https://bit.ly/ddbSupport target=_blank><img src=https://i.imgur.com/peaYpjh.png style=height:28px></a></center><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2018-05-31</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://taetaetae.github.io/2018/05/31/anomaly-detection/ data-title="시계열 데이터를 분석하여 미래 예측 하기(Anomaly Detection)" data-hashtags="python,anomaly detection,elasticsearch,prophet,facebook,archives-2018"><i class="fab fa-twitter fa-fw"></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://taetaetae.github.io/2018/05/31/anomaly-detection/ data-hashtag=python><i class="fab fa-facebook-square fa-fw"></i></a><a href=javascript:void(0); title="Share on Linkedin" data-sharer=linkedin data-url=https://taetaetae.github.io/2018/05/31/anomaly-detection/><i class="fab fa-linkedin fa-fw"></i></a><a href=javascript:void(0); title="Share on Blogger" data-sharer=blogger data-url=https://taetaetae.github.io/2018/05/31/anomaly-detection/ data-title="시계열 데이터를 분석하여 미래 예측 하기(Anomaly Detection)" data-description><i class="fab fa-blogger fa-fw"></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/python/>python</a>,&nbsp;<a href=/tags/anomaly-detection/>anomaly detection</a>,&nbsp;<a href=/tags/elasticsearch/>elasticsearch</a>,&nbsp;<a href=/tags/prophet/>prophet</a>,&nbsp;<a href=/tags/facebook/>facebook</a>,&nbsp;<a href=/tags/archives-2018/>archives-2018</a></section><section><span><a href=javascript:void(0); onclick=window.history.back();>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/2018/04/29/apache-408-response-code/ class=prev rel=prev title="아파치 엑세스 로그에 408코드가?"><i class="fas fa-angle-left fa-fw"></i>아파치 엑세스 로그에 408코드가?</a>
<a href=/2018/06/27/apache-vs-nginx/ class=next rel=next title="Apache냐 Nginx냐, 그것이 알고싶다.">Apache냐 Nginx냐, 그것이 알고싶다.<i class="fas fa-angle-right fa-fw"></i></a></div></div><div id=comments><div id=utterances></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://utteranc.es/>Utterances</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line>Powered by <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.74.3">Hugo</a> | Theme - <a href=https://github.com/dillonzq/LoveIt target=_blank rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i>LoveIt</a></div><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2016 - 2024</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=https://taetaetae.github.io/resume target=_blank>태태태</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw"></i></a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw"></i></a></div><link rel=stylesheet href=/lib/lightgallery/lightgallery.min.css><script type=text/javascript src=/lib/smooth-scroll/smooth-scroll.min.js></script><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/lightgallery/lightgallery.min.js></script><script type=text/javascript src=/lib/lightgallery/lg-thumbnail.min.js></script><script type=text/javascript src=/lib/lightgallery/lg-zoom.min.js></script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/sharer/sharer.min.js></script><script type=text/javascript>window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":500},"comment":{"utterances":{"darkTheme":"github-dark","issueTerm":"pathname","label":"Comment","lightTheme":"github-light","repo":"taetaetae/blog-comment"}},"lightGallery":{"actualSize":false,"exThumbImage":"data-thumbnail","hideBarsDelay":2000,"selector":".lightgallery","speed":400,"thumbContHeight":80,"thumbWidth":80,"thumbnail":true}};</script><script type=text/javascript src=/js/theme.min.js></script><script type=text/javascript>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js',new Date());gtag('config','UA-86432198-1',{'anonymize_ip':true});</script><script type=text/javascript src="https://www.googletagmanager.com/gtag/js?id=UA-86432198-1" async></script></body></html>