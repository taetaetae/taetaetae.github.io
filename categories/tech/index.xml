<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Tech - Category - 👨‍💻꿈꾸는 태태태의 공간</title><link>https://taetaetae.github.io/categories/tech/</link><description>Tech - Category - 👨‍💻꿈꾸는 태태태의 공간</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sun, 06 Dec 2020 20:19:47 +0900</lastBuildDate><atom:link href="https://taetaetae.github.io/categories/tech/" rel="self" type="application/rss+xml"/><item><title>Jenkins Job을 병렬로 실행해서 속도를 개선해보자. (feat. Pipeline)</title><link>https://taetaetae.github.io/posts/jenkins-job-parallel-processing-by-pipeline/</link><pubDate>Sun, 06 Dec 2020 20:19:47 +0900</pubDate><author>Author</author><guid>https://taetaetae.github.io/posts/jenkins-job-parallel-processing-by-pipeline/</guid><description><![CDATA[<div class="featured-image">
                <img src="/images/jenkins-job-parallel-processing-by-pipeline/pipeline.jpg" referrerpolicy="no-referrer">
            </div>﻿　관리하는 URL이 200응답을 주고 있는지 모니터링을 한다고 가정해보자. 다양한 방법이 생각나겠지만 가장 처음으로 떠오른 건 단연 Jenkins. 간단하게 사용할 언어에 맞춰 Execute Script를 작성하고 스케줄링을 걸어 놓으면 큰 수고 없이 모니터링을 구성할 수 있게 된다. 아래는 python script로 작성해 보았다.
import requests url=&#34;http://모니터링url&#34; status_code = requests.get(url).status_code if status_code != 200: print(f&#39;응답 실패 :{url}, status : {status_code}&#39;) exit(1) ﻿　하지만 모니터링을 해야 하는 URL이 1개에서 여러 개로 늘어난다면 어떻게 될까? 단순하게 작성한 Script를 아래처럼 약간 수정하면 되긴 하지만 URL마다 응답속도가 다를 경우 순차적으로 실행하다 보니 실행 속도는 느릴 수밖에 없다.
import requests urls = [ &#34;http://모니터링url-1&#34;, &#34;http://모니터링url-2&#34;, &#34;http://모니터링url-3&#34; ] for url in urls: status_code = requests.get(url).status_code if status_code != 200: print(f&#39;응답 실패 :{url}, status : {status_code}&#39;) exit(1) ﻿ 이러한 경우, 빠른 속도를 보장하기 위해서는 병렬로 실행을 해야 한다는 건 누구나 다 알지만 그렇다고 Thread를 사용하기엔 벌써부터 덜컥 부담이 된다. 그렇다고 Job을 URL 개수만큼 늘리기에는 배보다 배꼽이 더 커버리고&hellip; 그러다 발견한 기능이 바로 Jenkins Pipeline!
　이번 포스팅에서는 Jenkins Job을 동시에 여러 번 사용해야 하는 경우를 Pipeline을 통해서 개선한 내용에 대하여 공유해보려 한다. Jenkins Pipeline에 대해 들어만 봤는데 이번에 실제로 사용해보니 생각보다 쉽게 개선할 수 있었고 옵션들을 상황에 맞게 조합을 잘 한다면 상당히 활용성이 높아 보이는 기능인 것 같다.
기존상황 　테﻿스트를 위해 임의로 느린 응답을 생성하도록 URL을 구성하고 위에서 이야기했던 것처럼 Job 하나에 아주 심플하게 Python script를 작성하고 실행해보도록 하자. 임의로 느린 응답은 http://slowwly.robertomurray.co.uk/ 에서 제공하는 기능을 활용하였다.﻿
import requests urls = [ &#34;http://slowwly.robertomurray.co.uk/delay/0/url/https://www.naver.com/&#34;, &#34;http://slowwly.robertomurray.co.uk/delay/100/url/https://www.naver.com/&#34;, &#34;http://slowwly.robertomurray.co.uk/delay/200/url/https://www.naver.com/&#34;, &#34;http://slowwly.robertomurray.co.uk/delay/500/url/https://www.naver.com/&#34;, &#34;http://slowwly.robertomurray.co.uk/delay/1000/url/https://www.naver.com/&#34;, &#34;http://slowwly.robertomurray.co.uk/delay/2000/url/https://www.naver.com/&#34;, &#34;http://slowwly.robertomurray.co.uk/delay/5000/url/https://www.naver.com/&#34;, &#34;http://slowwly.robertomurray.co.uk/delay/10000/url/https://www.naver.com/&#34;, &#34;http://slowwly.robertomurray.co.uk/delay/20000/url/https://www.naver.com/&#34; ] for url in urls: status_code = requests.get(url).status_code if status_code != 200: print(f&#39;응답 실패 :{url}, status : {status_code}&#39;) exit(1) print(f&#39;응답성공 : {url}&#39;) 그래서 실행해보면 50초가 소요되었다. 자, 이제 개선을 해보자!
개선을 해보자 　﻿전체적인 개선의 흐름은 하나의 Job에 모니터링하고자 하는 url을 파라미터로 받아서 처리할 수 있도록 설정하고, 이를 Jenkins Pipeline 을 통해 여러 URL을 동시에 모니터링하게 구성하는 것이다. 그러면 두 개의 Job(파라미터로 받아 모니터링하는 Job, Jenkins Pipeline Job) 만으로 보다 빠르고 효율적인 구성을 할 수 있을 것으로 상상을 하고.
Job을 범용적으로 (Jenkins paramters 활용) 　﻿위에서 샘플로 작성하였던 Python script는 url 이 늘어날수록 Job 안에 script를 수정해야 한다. 그렇게 해도 무방하지만 이번 개선의 목표는 하나의 Job을 Pipeline 이 병렬로 컨트롤하도록 설정해야 했기 때문에 Jenkins Job에 파라미터를 받을 수 있도록 아래처럼 Jenkins Job 설정에 파라미터를 설정하고 Python script 또한 수정해 주자.
﻿Job &gt; 구성 &gt; 이 빌드는 매개변수가 있습니다" ﻿Job &gt; 구성 &gt; 이 빌드는 매개변수가 있습니다  import requests, os url = os.environ[&#39;url&#39;] status_code = requests.get(url).status_code if status_code != 200: print(f&#39;응답 실패 :{url}, status : {status_code}&#39;) exit(1) print(f&#39;응답성공 : {url}&#39;) 병렬 실행을 위한 Jenkins 설정 　﻿Jenkins Job 을 생성하면 기본적으로 Job마다의 대기열(Queue)이 있어 Job이 실행 중이라면 시작된 시간 순서대로 기다렸다가 앞선 Job이 종료가 되면 이어서 실행되는 구조이다. 하지만 우리는 Job을 병렬로 실행해야 했기에 Job 설정 중 필요한 경우 concurrent 빌드 실행 옵션을 켜줘서 기다리지 않고 병렬로 실행될 수 있도록 해준다.
﻿Job &gt; 구성 &gt; 필요한 경우 concurrent 빌드 실행" ﻿Job &gt; 구성 &gt; 필요한 경우 concurrent 빌드 실행  　﻿또한 Jenkins Job 자체는 병렬로 실행되도록 설정되었다 해도 기본적으로 Jenkins 자체의 대기열은 한정되어 있기 때문에 적당히 늘려줘서 여러 개의 Job이 대기 열 없이 동시에 실행될 수 있도록 해준다.]]></description></item><item><title>기술블로그 개편기 (by HUGO)</title><link>https://taetaetae.github.io/posts/blog-reorganization-by-hugo/</link><pubDate>Sun, 29 Nov 2020 18:12:15 +0900</pubDate><author>Author</author><guid>https://taetaetae.github.io/posts/blog-reorganization-by-hugo/</guid><description><![CDATA[<div class="featured-image">
                <img src="/images/blog-reorganization-by-hugo/hexo_to_hugo.png" referrerpolicy="no-referrer">
            </div>웹서비스 개발자라면 나만의 블로그쯤은 있어야지 하며 기술 블로그를 시작한 지도 어느덧 4년이 되었다. 처음엔 그저 새로 알게 된 기술이나 삽질하며 경험한 것들 중에 핵심만을 적어놓는 수준이었다. (지금 다시 보면 뭔가 오글거리는 건 기분 탓이겠지&hellip;) 그렇게 계속 글을 써오면서 글쓰기라는 것에 관심을 갖게 되고 내 글이 누군가에게 도움이 될 거라는 기대에 조금이라도 글을 잘 써보고자 단순 기록 용이 아닌 하나의 &lsquo;글&rsquo;을 쓰려고 노력해 온 것 같다.
　일주일에 한 개는 써야지. 한 달에 한 개는 써야지. 하며 자꾸 나 자신과의 타협을 하다가 최근에는 회사에서 운영하는 서비스 개편 때문에 정신없이 바쁘다는 핑계로 &lsquo;블로그&rsquo;에 &lsquo;ㅂ&rsquo;자도 생각하지 못하게 된다. 무엇이 문제일까?라는 생각은 결국 내 기술 블로그도 회사 서비스처럼 &lsquo;개편&rsquo;을 해보자는 생각으로 도달하게 되었고 간단할 것만 같았던 기술 블로그 개편 작업은 꽤 오랫동안 + 다양한 삽질들로 작업을 하게 된다.
　이번 포스팅에서는 기술 블로그를 개편하며 겪었던 내용들에 대해 정리해보고자 한다. 기존에 기술 블로그를 운영하시는 분들이나 이번에 새롭게 시작하시는 분들께 도움이 될 거라 기대한다. 더불어 서비스 &lsquo;출시&rsquo; 가 아닌 개편&rsquo;이라는 과정 속에서 느끼게 되었던 인사이트도 간략하게 작성해볼까 한다.
기술블로그 플랫폼 선택 　처음 블로그를 쓰기 시작했을 때 포털서비스의 글쓰기 플랫폼을 사용하지 않은 이유는 단 하나다. &lsquo;글쓰기&rsquo; 뿐만 아니라 개발자이기에 웹사이트(블로그)를 내 입맛에 맞게 커스터마이징 하기 위해서. 그 이유로 hexo 라는 프레임워크에 github의 호스팅을 사용하여 운영을 해왔다. 그렇게 블로그를 운영해오면서 느꼈던 불편했던 부분들과 개편을 하며 기대하는 부분들을 정리하면 아래와 같다.
 테마(UI)가 이뻐야 하고 기능들이 많으면 좋겠다. 기술 블로그인 만큼 코드가 많이 삽입되니 코드 표현 또한 이뻐야 한다. 테마 또는 프레임워크의 커뮤니티가 활발해야 한다. 페이지 생성 또는 만들어진 웹페이지의 성능이 좋아야 한다. 글을 작성하고 배포하는 과정이 심플하고 깔끔해야 한다. ﻿  　위와 같은 이유를 기반으로 검색을 해보다 SSG(쓱 쇼핑몰 아님, Static site generators)를 깔끔하게 정리해 놓은 사이트를 발견한다. 정말 다양한 플랫폼들을 살펴보며 필자에게 맞는 게 어떤 건지 고민하다 결국 hugo 를 선택하게 된다. hugo를 선택한 이유는 go라는 언어를 사용한다는 것과 (간접적으로라도 다른 언어를 경험해보고 싶어서 + go 언어가 빠르다는 소리를 어디선가 들어서) 테마들이 너무 다양했기 때문이다.
﻿아주 대놓고 빠르다고 하니&hellip; 쓰고 싶어진다." ﻿아주 대놓고 빠르다고 하니&hellip; 쓰고 싶어진다.  　결국 hugo에 hugo-ranking-trend라는 사이트에서 상위에 랭크가 되어있고 기술 블로그 성격에 적합할 것 같은 LoveIt이라는 테마를 사용하기로 결정하였다. 자 그럼 시작해볼까?!
hugo 는 어떻게 쓰는거야? ﻿　대부분의 오픈소스는 hello world 혹은 quick start 같이 처음 접하는 사람들을 위한 도큐먼트가 있기 마련. hugo도 마찬가지로 quick-start가 있었고 이를 천천히 따라 하면 생각보다 쉽게 초기 세팅을 할 수 있었&hellip; 을꺼라 기대했지만 약간 초기 설정 과정이 어려워서 남겨 두고자 한다.
 참고로 필자는 윈도 10 환경에서 구성하였다. mac이라면 더 쉽게 설정할 수 있는 것 같은데 이 부분은 OS의 차이에서 생겨나는 어쩔 수 없는 약간의 장벽이라 생각한다. 이쁜 테마와 새로운 환경을 사용할 수 있다는 기대감으로 꾹 참아본다.
 기본설정 　﻿git이 설치되어 있다는 가정하에 우선 hugo는 go 언어기반으로 돌아가기에 우선 go를 설치해야 한다. 다운로드페이지에서 환경에 맞는 설치 파일을 다운로드하고 설치를 해준다. 다음으로 패키지 관리자인 chocolatey 또한 설치가 필요하다. 공식 홈페이지페이지에서 나와있는 순서대로 진행하면 설치 완료. 필자는 여기서 진행이 잘 안됐었는데, &lsquo;관리자 권한&rsquo;으로 PowerShell 을 실행시켜야지만 성공을 할 수 있었다.﻿
﻿　위 설정이 완료되었으면 드디어 hugo를 설치해 주고 초기화를 해준 뒤 샘플로 글 하나를 만들고 서버를 띄우면 끝.
# chocolatey 에 의해 hugo 설치 choco install hugo -confirm # hugo 초기화 hugo new site quickstart # post 생성 hugo new posts/post-name.]]></description></item><item><title>빌드/테스트는 내가 해줄게. 너는 코딩에 집중해 (by GitHub Pull Request Builder)</title><link>https://taetaetae.github.io/2020/09/07/github-pullrequest-build/</link><pubDate>Mon, 07 Sep 2020 10:09:56 +0000</pubDate><author>Author</author><guid>https://taetaetae.github.io/2020/09/07/github-pullrequest-build/</guid><description><![CDATA[git 은 분산 버전 관리 시스템 중 가장 잘 알려져 있다고 해도 과언이 아닐 정도로 대부분의 시스템에서 사용되고 있는 것 같다. 이를 웹서비스에서 보다 편하게 사용할 수 있도록 한 시스템이 Github. Github 을 사용하는 이유 중에 가장 큰 이유를 하나만 이야기해보자면 바로 온라인상에서 코드 리뷰를 할 수 있는 pullRequest라는 기능 때문이 아닐까 조심스럽게 생각을 해본다.
　pullRequest는 work branch에서 작업한 내용을 base branch로 merge 전 꼭 코드 리뷰가 아니더라도 작업한 내용에 대해서 다양한 검사를 자동화할 수 있는 강력한 기능들이 많다. 이러한 자동화는 CI(지속적 통합) 관점에서 매우 중요한데 코드에 대해 체크해야 할 부분들(빌드, 테스트, 정적 분석 등)을 &ldquo;알아서&rdquo; 해준다면 작업자는 오롯이 비즈니스 로직 개발에 대해서만 신경 쓸 수 있으니 생산성 절약 측면에서 엄청난 효과를 볼 수 있다.
내가 하는일에만 집중할 수 있게! 출처 : https://www.clien.net/service/board/park/10453442" 내가 하는일에만 집중할 수 있게! 출처 : https://www.clien.net/service/board/park/10453442  이번 포스팅에서는 그중에서도 아주 간단한 설정만으로 work branch의 빌드 상태를 검사해 볼 수 있는 Jenkins의 Github Pull Request Builder를 설치 및 활용해 보고자 한다.
 사실 최근 팀에서 CI 서버를 이전해야 했었다. 머릿속에서는 어떻게 하면 되겠지 싶었지만 막상 해보려니 Jenkins 버전업도 되었고 뭐부터 해야 할지 허둥대는 필자가 부끄러웠다. 이참에 정리를 해보며 다시 한번 리마인드 하는 시간을 가져보고자 한다. (이래서 기억보다 기록이 중요하다.)
 준비물 　전체적인 흐름은 아래 그림처럼 흘러가기 때문에 당연히 서버에 Jenkins 가 설치되어 있어야 한다. Jenkins 설치는 필자의 포스팅(Jenkins 설치 치트키)를 참고해 보는 것도 좋을 것 같다.
전체적인 흐름" 전체적인 흐름  　참고로 필자는 GitHub Enterprise 버전에서 사용했는데 일반 Github에서도 동일한 방법으로 사용 가능하다.
Github과 Jenkins의 연동을 위한 2가지 설정 　Github 과 Jenkins 가 통신이 되도록 설정해 줘야 한다. 그래야 Github의 코드를 받아서 Jenkins 가 빌드를 하고 그 빌드 결과를 다시 Github에 리포트가 가능해지기 때문이다. 먼저 첫 번째로 ssh 설정으로 Github의 코드를 가져오도록 ssh 설정을 해두자. ssh 설정하는 방법은 필자의 포스팅(Github과 Jenkins 연동하기)편을 확인해보면 될 것 같다.
　그다음으로 아래에서 이야기할 GitHub Pull Request Builder라는 Jenkins plugin 이 빌드가 끝난 뒤에 결과를 리포팅 해줄 수 있는 인증 토큰을 발급받아두자. Github &gt; Settings &gt; Developer settings &gt; Personal access tokens 화면에서 키를 생성하고 만들어진 키를 저장해 둔다. (이 키는 보안에 유의해야 하고, 화면 경고(?)에서도 볼 수 있듯이 키는 생성 시 한 번밖에 볼 수 없기 때문에 미리 저장해 둬야 한다.)
인증토큰을 미리 받아두자." 인증토큰을 미리 받아두자.  Jenkins 설정 　Jenkins &gt; 관리 &gt; pluginManager에 들어가 GitHub Pull Request Builder를 검색 후 설치해 준다. 그러고 나서 Jenkins &gt; 관리 &gt; 환경설정에 들어가 보면 아래와 같이 GitHub Pull Request Builder 항목이 생긴 것을 확인할 수 있고 위에서 설정한 인증토큰을 아래처럼 등록 후 저장을 한다.
credentials 을 위에서 발급받은 인증토큰으로 등록해준다." credentials 을 위에서 발급받은 인증토큰으로 등록해준다.  　Jenkins job을 하나 만들고 pullRequest 가 발생했을 때 자동으로 실행될 수 있도록 설정을 해준다. 먼저 General 탭에 Github project에 Github url 을 적어주고
 　소스 코드 관리 탭에서 ssh 주소를 적고 위에서 미리 설정한 ssh 키로 credentials 값을 넣어준다. 전에도 이야기했지만 이 부분에서 오류가 발생하면 빨간색 글씨로 오류 내용이 나오고 아래 화면처럼 오류가 없다면 아무것도 안 나온다. Refspec 에 +refs/pull/*:refs/remotes/origin/pr/* 라고 적어주고 브랜치 설정은 파라미터로 받아와서 pullRequest를 발생시킨 브랜치를 빌드 할 수 있도록 ${sha1} 라고 적어주자.]]></description></item><item><title>스프링 부트에 필터를 '조심해서' 사용하는 두 가지 방법</title><link>https://taetaetae.github.io/2020/04/06/spring-boot-filter/</link><pubDate>Mon, 06 Apr 2020 23:59:36 +0000</pubDate><author>Author</author><guid>https://taetaetae.github.io/2020/04/06/spring-boot-filter/</guid><description><![CDATA[웹 어플리케이션에서 필터를 사용하면 중복으로 처리되는 내용을 한곳에서 처리할 수 있다거나 서비스의 다양한 니즈를 충족시키기에 안성맞춤인 장치인것 같다. 필터란 무엇인가 에 대한 내용은 워낙에 다른 블로그나 공식 도큐먼트에서 자세하게 그리고 다양하게 설명하고 있기에 기본 개념에 대해서는 설명하지 않도록 하려 한다. 이번 포스팅에서는 스프링 부트를 사용하면서 어노테이션이라는 간편함에 취해(?) &ldquo;돌격 앞으로, 닥공&rdquo; 의 자세로 개발을 하려했던 필자를 보고 &ldquo;반성&quot;의 자세로 필터를 등록하는 방법에 대해 명확하게 정리를 하고자 한다. 마지막으로는 아주 간단하면서도 엄청나게 위험한 필터 설정 사례에 대해서도 짚고 넘어가보자. 그냥 넘어가면 아쉬우니, 한번이라도 &lsquo;spring&rsquo; 이라는 framework 를 접해본 사람이라면 봤을법한 그림을 첨부하는것으로 필터란 무엇인가 에 대한 설명을 대신하는게 좋겠다.
출처 : https://justforchangesake.wordpress.com/2014/05/07/spring-mvc-request-life-cycle/" 출처 : https://justforchangesake.wordpress.com/2014/05/07/spring-mvc-request-life-cycle/  방법을 설명하기 전에 동일하게 사용될 필터와 컨트롤러 코드를 보면 다음과 같다.
 필터  @Slf4j public class MyFilter implements Filter { @Override public void init(FilterConfig filterConfig) throws ServletException { log.info(&#34;init MyFilter&#34;); } @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { log.info(&#34;doFilter MyFilter, uri : {}&#34;, ((HttpServletRequest)servletRequest).getRequestURI()); filterChain.doFilter(servletRequest, servletResponse); } @Override public void destroy() { log.info(&#34;destroy MyFilter&#34;); } }  테스트 할 컨트롤러  @Slf4j @RestController public class SampleController { @GetMapping(&#34;/test&#34;) public String test() { return &#34;test&#34;; } @GetMapping(&#34;/filtered/test&#34;) public String filteredTest() { return &#34;filtered&#34;; } } 방법 1 : FilterRegistrationBean 아주 간단하게, 일반 url 하나와 필터에 적용할 url 두개를 만들고 설정하려 한다. FilterRegistrationBean 을 이용해서 위에서 만들었던 필터를 아래처럼 등록해보자.
@SpringBootApplication public class Method1Application { public static void main(String[] args) { SpringApplication.run(Method1Application.class, args); } @Bean public FilterRegistrationBean setFilterRegistration() { FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(new MyFilter()); // filterRegistrationBean.setUrlPatterns(Collections.singletonList(&#34;/filtered/*&#34;)); // list 를 받는 메소드 	filterRegistrationBean.addUrlPatterns(&#34;/filtered/*&#34;); // string 여러개를 가변인자로 받는 메소드 	return filterRegistrationBean; } } 위 주석에도 적었지만 filterRegistrationBean 의 &ldquo;setUrlPatterns&rdquo; 와 &ldquo;addUrlPatterns&rdquo; 의 차이는 별거 없다. list 자체를 받을건지 아니면 가변인자로 계속 추가 할것인지. 이렇게 되면 &ldquo;/filtered/&ldquo;으로 &ldquo;시작&quot;하는 패턴의 url의 요청이 오게 되면 등록한 필터를 통과하게 된다.
 실행 : 필터 생성  /\\ / ___&#39;_ __ _ _(_)_ __ __ _ \ \ \ \ ( ( )\___ | &#39;_ | &#39;_| | &#39;_ \/ _` | \ \ \ \  \\/ ___)| |_)| | | | | || (_| | ) ) ) ) &#39; |____| .__|_| |_|_| |_\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.2.6.RELEASE) 2020-04-06 23:45:01.225 INFO 14672 --- [ main] c.t.s.method1.Method1Application : No active profile set, falling back to default profiles: default 2020-04-06 23:45:02.153 INFO 14672 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http) 2020-04-06 23:45:02.168 INFO 14672 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat] 2020-04-06 23:45:02.168 INFO 14672 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.33] 2020-04-06 23:45:02.361 INFO 14672 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext 2020-04-06 23:45:02.362 DEBUG 14672 --- [ main] o.s.web.context.ContextLoader : Published root WebApplicationContext as ServletContext attribute with name [org.springframework.web.context.WebApplicationContext.ROOT] 2020-04-06 23:45:02.362 INFO 14672 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 1082 ms 2020-04-06 23:45:02.391 DEBUG 14672 --- [ main] o.s.b.w.s.ServletContextInitializerBeans : Mapping filters: filterRegistrationBean urls=[/filtered/*] order=2147483647, characterEncodingFilter urls=[/*] order=-2147483648, formContentFilter urls=[/*] order=-9900, requestContextFilter urls=[/*] order=-105 2020-04-06 23:45:02.391 DEBUG 14672 --- [ main] o.]]></description></item><item><title>조금 더 괜찮은 Rest Template 2부 - Circuit-breaker</title><link>https://taetaetae.github.io/2020/03/29/better-rest-template-2-netflix-hystrix/</link><pubDate>Sun, 29 Mar 2020 23:09:16 +0000</pubDate><author>Author</author><guid>https://taetaetae.github.io/2020/03/29/better-rest-template-2-netflix-hystrix/</guid><description><![CDATA[<div class="featured-image">
                <img src="/images/better-rest-template-2-netflix-hystrix/netflix_hystrix.jpg" referrerpolicy="no-referrer">
            </div>지난 포스팅에서는 Retryable 를 활용해서 간헐적인 네트워크 오류를 &ldquo;재시도&quot;를 함으로써 아주 간단하면서도 강력하게 해결할 수 있는 방법에 대해 알아보았다. 실제로 필자가 운영하는 서비스 에서도 Retryable 를 이용하기 전과 후를 비교해보면 간헐적인 네트워크 오류의 빈도수가 확실히 줄어든것을 확인할 수 있었다. 이렇게 &ldquo;재시도&quot;를 해서 요청했을때 성공 응답을 받을 경우엔 문제가 안되지만 네트워크 오류가 아닌 실제로 호출을 받는 해당 서버에서 문제가 발생했다면 어떨까? 예컨대, 해당 서버에서 DB를 조회하는 API를 호출한다고 가정했을때 DB 자체에서 어떠한 오류가 난다면. 이런 경우는 단순히 &ldquo;재시도&quot;로 해결할 수 없는 문제다.
물론 Retryable 의 Recover 어노테이션을 활용했기 때문에 클라이언트 즉, 사용자에게는 오류응답이 발생을 안했겠지만 호출 받는 서버 자체에서의 에러가 발생하는데 이런식의 재시도를 계속 시도한다면 호출 받는 서버 입장에서는 이 &ldquo;재시도&rdquo; request 또한 &ldquo;부하&rdquo; 로 받게 되고 결국 2차, 3차 장애가 이어질 수 밖에 없다.
기존 한덩어리로 관리되던 Monolithic Architecture 에서는 자체적으로 관리하기 때문에 이러한 에러 컨트롤 또한 자체적으로 관리를 할 수 있지만, 모듈이 모듈을 호출하게 되는 Microservice Architecture 로 바뀌다보니 이런 &ldquo;연쇄 장애(?)&rdquo; 같은 현상이 발생하게 되는 경우가 있다. 호출을 받는 서버의 상태가 이상하면 (에러응답이 지정한 임계치를 벗어나는 수준으로 맞춰서 발생한다면) 적절하게 호출을 하지 않고 (2차 장애를 내지 않도록 호출 자체를 하지 않고) 어느정도 기다리다 클라이언트에게는 에러응답이 아닌 미리 정해둔 응답을 내려주고, 에러가 복구되면 다시 호출하도록 하는 &ldquo;무언가&rdquo; 가 필요하지 않을까?
연쇄 장애. 제발 멈춰&hellip; 출처 : http://dpg.danawa.com/mobile/community/view?boardSeq=175&amp;listSeq=4066389" 연쇄 장애. 제발 멈춰&hellip; 출처 : http://dpg.danawa.com/mobile/community/view?boardSeq=175&amp;listSeq=4066389  지난 포스팅에 이어 이번 포스팅 에서는 그 &ldquo;무언가&rdquo;. 즉, Circuit-breaker 에 대해 알아보고 직접 구현 및 테스트 하면서 돌아가는 원리에 대해 이해 해보고자 한다. 막상 개념은 머릿속에 있지만 직접 구현해보지 않으면 내것이 아니기에, 직접 구현하고 설정값들을 바꿔가면서 언젠가 필요한 순간에 꺼내서 사용할 수 있는 나만의 &ldquo;무기&rdquo; 를 만들어 보고자 한다.
Circuit breaker ? (한국 발음으로) 서킷브레이커를 검색해보면 주식시장 관련된 내용이 꽤 나온다. (앗, 잠깐 눈물좀&hellip;) 서킷 브레이커. 이 용어는 다양한 곳에서 사용되는데 &ldquo;회로 차단기&rdquo; 라고도 검색이 된다. 해당 내용을 발췌해보면 다음과 같다.
 회로 차단기는 전기 회로에서 과부하가 걸리거나 단락으로 인한 피해를 막기 위해 자동으로 회로를 정지시키는 장치이다. 과부하 차단기와 누전 차단기로 나뉜다. 퓨즈와 다른 점은, 차단기는 어느 정도 시간이 지난 뒤, 원래의 기능이 동작하도록 복귀된다.
 여기서 가장 중요한 문장은 &ldquo;피해를 막기 위해 자동으로 회로를 정지시키는&rdquo;, &ldquo;어느정도 시간이 지난뒤 원래의 기능이 동작하도록 복귀된다&rdquo; 이 부분이 가장 중요한 것 같다. 시스템 구성이 점점 Microservice Architecture 로 바뀌어 가는 시점에서 이러한 &ldquo;서킷브레이커&quot;는 자동으로 모듈간의 호출 에러를 감지하고 위에서 말한 &ldquo;연쇄 장애&quot;를 사전에 막을 수 있는 아주 중요한 기능이라 생각된다.
&ldquo;circuit breaker spring&rdquo; 이라는 키워드로 검색해보면 이러한 고민을 이미 Netflix 라는 회사에서 Hystrix 라는 이름으로 개발이 된것을 알 수 있다. 이 core 모듈을 Spring 에서 한번 더 감싸서 Spring Boot 에서 사용하기 좋게 spring-cloud-starter-netflix-hystrix 라는 이름으로 만들어 둔 것이 있는데 이것을 활용해 보기로 하자.
구현 늘 그랬듯이 SpringBoot 프로젝트를 만들고 테스트할 Controller 를 만들어 주자. 원래대로라면 호출을 하는 모듈과 호출을 받는 모듈, 2개의 모듈을 만들어서 테스트 해야 하지만 편의를 위해 하나의 모듈에서 두개의 Controller 을 만들고 테스트 해보는 것으로 하자.
@RestController public class MainController { private final MainService mainService; @GetMapping(&#34;index&#34;) public String index(String key){ return mainService.getResult(key); } public MainController(MainService mainService) { this.mainService = mainService; } } @Slf4j @Service public class MainService { private RestTemplate restTemplate; public String getResult(String key) { return restTemplate.]]></description></item><item><title>조금 더 괜찮은 Rest Template 1부 - Retryable</title><link>https://taetaetae.github.io/2020/03/22/better-rest-template-1-retryable/</link><pubDate>Sun, 22 Mar 2020 15:30:35 +0000</pubDate><author>Author</author><guid>https://taetaetae.github.io/2020/03/22/better-rest-template-1-retryable/</guid><description><![CDATA[<div class="featured-image">
                <img src="/images/better-rest-template-1-retryable/icons8.png" referrerpolicy="no-referrer">
            </div>웹 어플리케이션을 만들면서 꼭 한번 쯤 만나게 되는 &ldquo;RestTemplate&rdquo;. 접근 가능한 외부 HTTP URL(보통 API)을 호출하는 방법중에 하나로 springframework 에서 제공해주는 모듈이다. 특히 큰 한덩어리로 관리되던 Monolithic Architecture 에서 요청을 하고(client) 응답을 주는(server) 즉, Endpoint가 작은 단위로 분리되는 Microservice Architecture 로 바뀌면서 각 서비스간 호출방식이 HTTP 일 경우 자주 사용되곤 하는 것 같다. (webClient 등 다른 여러 호출 방법들이 있다.) 만약, 요청을 하는 클라이언트 입장에서 응답을 주는 서버의 상태가 불안정 하다고 가정했을때, 어떤식으로 처리해야 할까? 예컨대, 요청 10번에 한번은 어떠한 이슈로 응답이 지연되거나 서버에러가 발생한다고 하면 클라이언트를 사용하는 사용자 입장에서는 간헐적인 오류응답에 답답함을 호소할 수도 있다. 그럼 잠시 눈을 감고 생각해보자. 가볍게 생각하면 아래처럼 아주 간단하게 &ldquo;예외처리&quot;를 이용할 수도 있다.
try { // http call } catch (Exception e){ // 서버에러가 아닌 약속된 에러응답을 리턴 } 하지만 이것도 정답이 아닐수 있는게, &ldquo;간헐적인 오류&quot;로 인해 사용자는 오류화면을 봐야하기 때문에 클라이언트에 대한 신뢰를 저버릴 수밖에 없다. 그럼 어떻게 해야할까? 여러가지 해결방법이 있겠지만 간단하면서도 강력하다고 생각되는 방법이 바로 &ldquo;재시도&rdquo; 라고 생각한다. 클라이언트를 사용하는 사용자가 눈치 못챌만큼 빠르게 재시도를 한다면 에러가 나도 다시한번 호출해서 성공할 수 있는 가능성이 높기 때문이다. (그치만 근본적인 원인은 해결해야&hellip;)
실제로 조금있다 해보면 되는 경우가 많으니 안될때는 조금 (천천히) 시도해보자. 출처 : http://www.segye.com/newsView/20200302504384" 실제로 조금있다 해보면 되는 경우가 많으니 안될때는 조금 (천천히) 시도해보자. 출처 : http://www.segye.com/newsView/20200302504384  이번 포스팅에서는 RestTemplate 를 이용할때 &ldquo;재시도&rdquo; 할 수 있는 방법에 대해 알아보고자 한다. 아주 간단할지 모르지만 노력에 비해 효과가 상당하다고 생각하기 때문에 정리해 두고 싶었다.
Spring Retry 공식 Github에 소개를 빌리자면, Spring 어플리케이션에 대한 재시도 지원을 제공한다고 한다. 위에서 이야기 했던 &ldquo;RestTemplate&quot;과는 사실 무관하고, 이를 활용해서 재시도 하는 &ldquo;RetryRestTemplate&quot;를 구현해보려 하는것이다. 우선 이 &ldquo;Spring-Retry&quot;의 예제를 보면 아주 심플하게 사용할 수 있다. 우선 pom에 구현에 필요한 dependency 를 추가하고 아래 코드를 보자.
&lt;dependency&gt; &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt; &lt;artifactId&gt;spring-retry&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; @Configuration @EnableRetry // 1 public class Application { @Bean public Service service() { return new Service(); } } @Service class Service { @Retryable(RemoteAccessException.class) // 2  public void service() { // ... do something  } @Recover // 3  public void recover(RemoteAccessException e) { // ... panic  } }  @EnableRetry 어노테이션을 @Configuration을 지정한 클래스 중 하나에 추가한다. 재시도 하려는 메소드에 @Retryable 어노테이션을 지정해준다. 재시도가 완료되는 시점에서 실행하고 싶을때 선언하는 어노테이션, @Retryable 동일한 클래스에서 선언되어야 하고 return type 은 @Retryable을 지정한 메소드와 동일해야 한다.  Retry Rest Template 이렇게 springframework 에서 제공해주는 spring-retry 를 이용해서 이번 포스팅의 목표인 재시도를 하는 Retry Rest Template 를 구성해보자. 우선, RestTemplate 를 Bean 으로 등록하고, 위에서 이야기 한 어노테이션들로 구성해보자.
@EnableRetry @Configuration public class RetryableRestTemplateConfiguration { @Bean public RestTemplate retryableRestTemplate() { SimpleClientHttpRequestFactory clientHttpRequestFactory = new SimpleClientHttpRequestFactory(); // 1 	clientHttpRequestFactory.setReadTimeout(2000); clientHttpRequestFactory.setConnectTimeout(500); RestTemplate restTemplate = new RestTemplate(clientHttpRequestFactory) { @Override @Retryable(value = RestClientException.class, maxAttempts = 3, backoff = @Backoff(delay = 1000)) // 2 	public &lt;T&gt; ResponseEntity&lt;T&gt; exchange(URI url, HttpMethod method, HttpEntity&lt;?&gt; requestEntity, Class&lt;T&gt; responseType) throws RestClientException { return super.exchange(url, method, requestEntity, responseType); } @Recover public &lt;T&gt; ResponseEntity&lt;String&gt; exchangeRecover(RestClientException e) { return ResponseEntity.badRequest().body(&#34;bad request T.T&#34;); // 3 	} }; return restTemplate; } }  SimpleClientHttpRequestFactory 를 만들고 각 타임아웃을 설정해준 다음 RestTemplate 파라미터로 넘겨준다. 사용하는 곳에서 exchange 메소드를 이용할 것이므로 해당 메소드를 오버라이드 해준다.]]></description></item><item><title>SpringRestDocs를 SpringBoot에 적용하기</title><link>https://taetaetae.github.io/2020/03/08/spring-rest-docs-in-spring-boot/</link><pubDate>Sun, 08 Mar 2020 23:16:59 +0000</pubDate><author>Author</author><guid>https://taetaetae.github.io/2020/03/08/spring-rest-docs-in-spring-boot/</guid><description><![CDATA[<div class="featured-image">
                <img src="/images/spring-rest-docs-in-spring-boot/logo.jpg" referrerpolicy="no-referrer">
            </div>API를 개발하고 제공하기 위해서는 그에 해당하는 API 명세를 작성해서 사용하는 곳에 전달하게 된다. 어떤 URL에 어떤 파라미터를 사용해서 어떻게 요청을 하면 어떤 결과를 응답으로 내려주는지에 대한 관련 정보들. 이러한 &ldquo;API 문서&rdquo; 를 제공하는 방식은 상황에 따라 다양한 방법으로 사용되곤 한다. API 코드와 해당 문서의 동기화가 자동으로 되어야 조금 편해질것 같다는 생각이 들었다. 출처 : https://dribbble.com/shots/3386291-API-Documentation" API 코드와 해당 문서의 동기화가 자동으로 되어야 조금 편해질것 같다는 생각이 들었다. 출처 : https://dribbble.com/shots/3386291-API-Documentation  필자는 주로 &ldquo;위키&rdquo;(또는 일반 문서)를 활용해서 전달하곤 했었는데 API의 형태가 달라질 때마다 해당 위키를 수정해야만 하는 번거로움이 있었다. API 수정하면 위키도 수정하고. 깜박하고 위키 수정을 안하게 될 경우 왜 API 명세가 다르냐는 문의가&hellip; 그러다 알게된 Spring Rest Docs. (아무리 좋은 기술, 좋은 툴 이라 해도 실제로 본인이 필요로 하고 사용을 해야하는 이유가 생길때 비로소 빛을 발하는것 같은 느낌이다.)
 이 포스팅에서는 swegger 와 비교하는 내용은 제외할까 한다. 워낙 유명한 두 양대 산맥(?)이라 검색해보면 각각의 장단점이 자세히 나와있기에&hellip;
 최근 들어 TestCode 의 중요성을 절실하게 느끼고 있었고, TestCode 를 작성하면 자연스럽게 문서를 만들어 주는 부분이 가장 매력적이라고 생각이 들었다. 이를 반대로 생각하면, TestCode 가 실패할 경우 빌드 자체가 안되기에 어쩔수 없이 TestCode를 성공시켜야만 하고, 자연스럽게 정상적인(최신화 된) API 문서가 만들어지게 된다.
이번 포스팅에서는 다음과 같은 목표를 두고 실무에서 언제든지 활용이 가능한 약간의 &ldquo;가이드&rdquo; 같은 내용으로 작성해 보고자 한다.
 Spring Boot 최신 버전에서 Spring Rest Docs 를 설정한다. 임의의 API 를 만들고 그에 따른 TestCase 를 작성한다. Spring.profile 에 따라 Spring Rest Docs Url 을 접근 가능/불가능 할 수 있게 한다.  물론 필자의 방법이 다를수도 있지만, 이러한 방법을 토대로 보다 더 우아하고 아름다운 방법을 알아갈수 있지 않을까 하는 기대로.
Spring Boot 에 Spring Rest Docs 셋팅하고 TestCase 작성하기 우선 Spring Boot 프로젝트를 만든다. https://start.spring.io/ 에서 만들어도 되고 IDE 에서 제공하는 툴로 만들어도 되고. 만드는 방식은 무방하다. 그 다음 필요한 dependency 를 추가해 준다.
&lt;dependency&gt; &lt;groupId&gt;org.springframework.restdocs&lt;/groupId&gt; &lt;artifactId&gt;spring-restdocs-mockmvc&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; 임의로 API를 작성하고
 모델  @Getter @Setter public class Book { private Integer id; private String title; private String author; }  컨트롤러  @RestController public class BookController { @GetMapping(&#34;/book/{id}&#34;) public Book getABook(@PathVariable Integer id) { Book book = new Book(); book.setId(id); book.setTitle(&#34;spring rest docs in spring boot&#34;); book.setAuthor(&#34;taetaetae&#34;); return book; } } 해당 컨트롤러에 대한 TestCase 를 작성하자.
@WebMvcTest(BookController.class) @AutoConfigureRestDocs // (1) public class BookControllerTest { @Autowired private MockMvc mockMvc; // (2)  @Test public void test_책을_조회하면_null이_아닌_객체를_리턴한다() throws Exception { mockMvc.perform(get(&#34;/book/{id}&#34;, 1) .accept(MediaType.APPLICATION_JSON)) .andDo(MockMvcResultHandlers.print()) .andExpect(MockMvcResultMatchers.status().isOk()) .andDo(document(&#34;book&#34;, // (3) 	pathParameters( parameterWithName(&#34;id&#34;).description(&#34;book unique id&#34;) // (4) 	), responseFields( fieldWithPath(&#34;id&#34;).description(&#34;book unique id&#34;), fieldWithPath(&#34;title&#34;).description(&#34;title&#34;), fieldWithPath(&#34;author&#34;).description(&#34;author&#34;) ) )) .andExpect(jsonPath(&#34;$.id&#34;, is(notNullValue()))) // (5) 	.andExpect(jsonPath(&#34;$.title&#34;, is(notNullValue()))) .andExpect(jsonPath(&#34;$.author&#34;, is(notNullValue()))); } } (1) Spring Boot 에서는 해당 어노테이션으로 여러줄에 걸쳐 설정해야 할 Spring Rest Docs 관련 설정을 아주 간단하게 해결할 수 있게 된다. (참고)
(2) 공식 도큐먼트 에서는 4가지 방식을 말하고 있는데 이 포스팅 에서는 &ldquo;MockMvc&rdquo; 을 사용하고자 한다.
(3) &ldquo;book&rdquo; 이라는 identifier 를 지정하면 해당 TestCase 가 수행될때 snippets 가 생성되는데 해당 identifier 묶음으로 생성이 된다.
(4) request의 파라미터 필드, response의 필드의 설명을 적어줌으로써 이 정보를 가지고 snippets 가 생성이 되고 결과적으로 API 문서가 만들어 진다.
(5) 필자가 가장 매력적이라 생각되는 부분. 이 부분에서 테스트를 동시에 함으로써 응답이 달라지거나 잘못된 응답이 내려올 경우 TestCase가 실패하게 되어 API문서 또한 생성되지 않게 된다.]]></description></item><item><title>Jupyter 설치하고 원격접속까지 (for 파.알.못)</title><link>https://taetaetae.github.io/2020/02/09/jupyter-install/</link><pubDate>Sun, 09 Feb 2020 20:06:15 +0000</pubDate><author>Author</author><guid>https://taetaetae.github.io/2020/02/09/jupyter-install/</guid><description><![CDATA[파이썬이라는 언어는 다른 프로그래밍 언어들에 비해 쉽고 직관적이라 그런지 프로그래밍을 처음 시작하는 사람들에게 더욱이 주목을 받고 있는것 같다. 정말 다양한 모듈들이 많아 여러분야에서 활용되고 있고 특히 언제부터인가 핫! 해진 분야(?)라 해도 과언이 아닐정도인 &ldquo;머신러닝&rdquo; 분야에서도 다양하게 사용되고 있는것 같다.
마침 필자가 속해 있는 팀 내에 머신러닝 스터디가 시작이 되었고, 그에 파이썬을 이용하여 스터디를 해야하는 상황. 하지만 스터디를 하는 팀원 절반 이상이 파이썬을 이용한 개발 경험이 없었고, 서로 배운것을 공유를 하면서 스터디를 하면 더 좋겠다는 생각이 들때 즈음. 언제 어디선가 봤던것이 머릿속을 스쳐 지나간다. 그건 바로 Jupyter(이하 주피터).
출처 : https://jupyter.org/" 출처 : https://jupyter.org/  주피터는 수십 개의 프로그래밍 언어에서 대화 형 컴퓨팅을위한 오픈 소스 소프트웨어, 오픈 표준 및 서비스를 개발하기 위한 툴이라고 한다. 이 포스트를 작성하기 전까지만 해도 &ldquo;주피터 == 파이썬 웹 개발툴&rdquo; 이라고만 알고있었는데 좀더 찾아보니 다양한 언어를 지원하는것 같다.
그럼 이러한 주피터를 특정 서버에 설치하고 로컬에 파이썬을 설치하지 않아도 원격으로 파이썬 코딩을 해보면 좀더 스터디에 도움이 되지 않을까 하는 마음이 들었다. 또한 학교에서 운동장에 잔디를 깔아서 맘껏 뛰놀수 있게 하는 느낌으로 팀원들을 위해 설치를 해두고 원격으로 접속할 수 있게 해두면 모두가 편하고 쉽게 파이썬에 대해 경험을 해볼 수 있지 않을까 하는 마음으로 주피터를 설치를 해 보고자 한다.
본 포스팅의 목표는 다음과 같다.
 환경 : CentOS 7.4 64Bit, python 2.7 (기본) 목표  anaconda 를 활용하여 시스템 기본 파이썬을 건드리지 않는 가상환경을 구축한다. 주피터를 설치하고 원격으로 접속할 수 있도록 설정한다.    여기까지 보면 필자가 엄청나게 파이썬에 대해 잘 아는것처럼 보일수도 있어 미리 말하지만 필자는 찐 자바 개발자이면서 파이썬 개발 수준은 기본적인 스크립트를 작성하는 정도이다. 그러니 이 포스트를 읽고 있는 필자같은 파알못(?) 분들도 충분히 설치가 가능하다. (최대한 따라할수 있을 정도의 치트키 수준으로 작성 하고자 한다.)
아나콘다 설치 (덤으로 설치되는 주피터) 우선 아나콘다를 설치하자. 아나콘다는 Anaconda(이전: Continuum Analytics)라는 곳에서 만든 파이썬 배포판으로, 수백 개의 파이썬 패키지를 포함하고 있다고 한다. 즉, 아나콘다를 설치하고 만들어진 가상환경에서 파이썬 개발을 하면 다양한 모듈이 이미 설치되어 있기 때문에 편리하다는 이야기.
출처 : https://www.anaconda.com/" 출처 : https://www.anaconda.com/  더불어 시스템에 기본으로 설치되어 있는 파이썬을 건드리면 여러 복잡한 문제가 발생할 수 있기에. 아나콘다를 활용하여 파이썬 3을 사용하는 가상환경을 만들어 보자. 설치는 아주 간단하다. 아나콘다 설치파일을 다운받고 이를 실행하면 끝. (user 레벨이 root 면 sudo 명령어를 생략해도 된다.)
$ wget https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh $ sudo bash Anaconda3-2019.10-Linux-x86_64.sh Welcome to Anaconda3 2019.10 In order to continue the installation process, please review the license agreement. Please, press ENTER to continue &gt;&gt;&gt; =================================== Anaconda End User License Agreement =================================== Copyright 2015, Anaconda, Inc. ~~~ 중략 ~~~ Do you accept the license terms? [yes|no] [no] &gt;&gt;&gt; yes # yes!! Anaconda3 will now be installed into this location: /root/anaconda3 - Press ENTER to confirm the location - Press CTRL-C to abort the installation - Or specify a different location below [/root/anaconda3] &gt;&gt;&gt; /home/anaconda3 # 설치될 경로를 설정해주고 기본 설정값에 설치하려면 그냥 엔터 ~~~뭐가 엄청 설치된다. 물 한잔 먹고 오자.~~~ installation finished. Do you wish the installer to initialize Anaconda3 by running conda init? [yes|no] [no] &gt;&gt;&gt; yes # yes!! 이렇게 되면 설치는 끝. 환경변수를 설정해서 기본 파이썬 환경을 아나콘다에 의해 설정되도록 맞춰주자.
sudo vi .bashrc __conda_setup=&#34;$(&#39;/home/anaconda3/bin/conda&#39; &#39;shell.bash&#39; &#39;hook&#39; 2&gt; /dev/null)&#34; if [ $? -eq 0 ]; then eval &#34;$__conda_setup&#34; else if [ -f &#34;/home/anaconda3/etc/profile.]]></description></item><item><title>스프링 부트로 멀티모듈 셋팅하기</title><link>https://taetaetae.github.io/2020/01/19/spring-boot-maven-multi-module/</link><pubDate>Sun, 19 Jan 2020 10:29:03 +0000</pubDate><author>Author</author><guid>https://taetaetae.github.io/2020/01/19/spring-boot-maven-multi-module/</guid><description><![CDATA[<div class="featured-image">
                <img src="/images/spring-boot-maven-multi-module/multimodule.png" referrerpolicy="no-referrer">
            </div>서비스를 처음 만들기 시작할때면 각 직군별로 생각하는 포인트가 다양하다. 설계, 기획, 디자인, 개발. 여기서 개발은 프로젝트 셋팅을 어떻게 해야하지? 하는 고민을 하기 마련이다. 아주 간단하게 하나의 모듈로 모든 기능을 담당하도록 만들 수 있지만 기능별로 모듈을 나눠서 셋팅하는게 관리측면에서 장점이라 생각한다.예를 들어보자. 도서관의 들어온 책 정보를 외부에 제공하는 &ldquo;API&rdquo;, 주기적으로 책 정보를 업데이트 하는 &ldquo;Batch&rdquo;. 이렇게 크게 두가지의 모듈이 있어야 한다고 가정했을때 어떤식으로 모듈을 설계할 수 있을까?
이번 포스팅에서는 스프링 부트와 메이븐을 활용해서 하나의 프로젝트(컴포넌트)에서 여러 모듈을 관리할 수 있는 Spring Multi Module을 셋팅하는 방법에 대해 알아보고자 한다. 필자도 셋팅하기 전에는 &ldquo;그냥 하면 되는거 아니야?&ldquo;라며 우습게 보다 아주 사소한 부분들에서 엄청난 삽질을 해서 그런지 꼭 포스팅으로 남겨놔야 겠다고 다짐했고 이렇게 정리를 할 수 있게 되어서 다행이라 생각한다.
어쩌면 우리가 있는 팀도 멀티모듈이 아닐까? 출처 : https://bcho.tistory.com/813" 어쩌면 우리가 있는 팀도 멀티모듈이 아닐까? 출처 : https://bcho.tistory.com/813  왜 멀티모듈로 셋팅할까? 위에서 예시로 이야기 한것처럼 현재 우리가 셋팅해야할 모듈은 크게 두가지 이다.
 API : 외부에 도서관에 들어온 책 정보를 알려주는 모듈 Batch : 주기적으로 도서관의 책 정보를 갱신하는 모듈  한번 생각을 해보자. 위에서 말한 모듈들 중에 동시에 사용할것만 같은 정보가 있다. &ldquo;책 정보&rdquo;. 각 모듈마다 &ldquo;책 정보&quot;를 가져오는 로직을 작성하는것 보다 한곳에서 해당로직을 구현하고 이를 여러곳에서 사용하는게 사용하는게 중복코드를 방지할수 있는 방법이란건 쉽게 알아차릴수 있다. 그렇다면 어떻게 모듈을 분리할수 있을까?
필자의 경험으로 미루어 볼때 크게 두가지 방법이 있는것 같다.
 공통으로 사용하는 모듈을 jar로 만들고 이를 메이븐 원격 저장소에 deploy, 사용하는 모듈에서 디펜던시에 추가하여 사용 멀티모듈로 구성하고 사용하는 모듈에서 디펜던시에 추가하여 사용  첫번째 방법의 가장 큰 단점은, 공통으로 사용하는 모듈이 변경될때마다 버전을 바꿔주고 (안바꿔도 되지만 사용하는 모듈에서 캐시 갱신을 해야하는 불편함이 생긴다.) 메이븐 원격 저장소에 deploy를 해줘야 한다. 그에 반해 두번째 방법은 이런과정없이 함께 빌드만 해주면 끝나고 IDE에서 개발시 한 모듈에서 동시에 수정과 사용이 가능하기 때문에 훨씬 편리하다.
은총알은 없다 라는 말처럼, 정답은 없다. 하지만 이런저런 방법들을 미리 알아두면 적시적소에 사용할 수 있는. 필자가 다른글들에서도 언급을 자주하던 &ldquo;나만의 무기&quot;가 되지 않을까?
멀티모듈 셋팅하기 위에서 이야기 했던 &ldquo;API&rdquo;, &ldquo;Batch&quot;와는 별도로 공통으로 사용하는 모듈인 &ldquo;Core&rdquo; 이렇게 총 3개의 모듈을 만들예정이다.
 다른 이야기지만, 공통으로 사용할 것 &ldquo;같아서&rdquo; 미리 공통로직을 작성하는 습관은 좋지 않는것 같다. 그러다보면 쓸데없이 공통로직이 무거워지므로 실제로 사용하면서 중복코드가 발생할때 그때 공통로직으로 리펙토링 해도 늦지 않는것 같다. (꼰데인가&hellip;)
 구현하는 환경은 다음과 같다.
 Spring Boot 2.2.3 Maven IntelliJ  우선 IDE의 힘을 빌려 하나의 스프링 부트 프로젝트를 생성해본다.
다음 &gt; 다음 &gt; 다음" 다음 &gt; 다음 &gt; 다음  그 다음 만든 프로젝트에서 우클릭 후 새로운 모듈을 선택. Maven 모듈을 선택하고 적당한 이름을 적어준다. 다음 &gt; 다음 &gt; 다음 222" 다음 &gt; 다음 &gt; 다음 222 
&ldquo;API&rdquo;, &ldquo;Batch&rdquo;, &ldquo;Core&rdquo; 라는 모듈을 추가하고 실제 모듈이 되는 &ldquo;API&rdquo;, &ldquo;Batch&quot;에 Build plugin 을 셋팅해주자. 그렇게 하고 각 Pom.xml을 보면 아래와 같다. (&ldquo;API&rdquo; 모듈에 대해서만 집중적으로 이야기 하려 한다. &ldquo;Batch&rdquo; 모듈도 동일한 형식으로 작성하기 때문.)
 최 상위 Pom.xml (library) modules 하위에 멀티모듈로 설정한 모듈들의 이름이 들어가 있는것을 확인할 수 있다.  &lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt; &lt;project xmlns=&#34;http://maven.apache.org/POM/4.0.0&#34; xmlns:xsi=&#34;http://www.w3.org/2001/XMLSchema-instance&#34; xsi:schemaLocation=&#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&#34;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;modules&gt; &lt;module&gt;api&lt;/module&gt; &lt;module&gt;core&lt;/module&gt; &lt;module&gt;batch&lt;/module&gt; &lt;/modules&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.taetaetae&lt;/groupId&gt; &lt;artifactId&gt;library&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;library&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.]]></description></item><item><title>더이상 기다리지 않아도 되는 배치 무중단 배포</title><link>https://taetaetae.github.io/2019/10/13/batch-nondisruptive-deploy/</link><pubDate>Sun, 13 Oct 2019 15:46:12 +0000</pubDate><author>Author</author><guid>https://taetaetae.github.io/2019/10/13/batch-nondisruptive-deploy/</guid><description><![CDATA[<div class="featured-image">
                <img src="/images/batch-nondisruptive-deploy/wait_illustration.jpg" referrerpolicy="no-referrer">
            </div>지난 포스팅, 그러니까 우아한 형제들에서 초대를 받아 Spring batch 에 대한 테크세미나에 다녀 왔다. 그 중 가장 인상깊었던 부분이 바로 무중단 배포. 차일피일 미루다 필자가 속한 팀에서도 배포때마다 가장 불편을 느끼고 있었던 부분이었기도 했고, 그런가보다 하며 개념만 알고 넘어가기엔 무언가 양심에 찔려 직접 무중단 배포를 할 수 있도록 구성을 해보고 테스트까지 해보고자 한다.
상황 및 문제점 리눅스 서버에 Jenkins가 설치되어 있고, Spring batch 모듈을 실행시키고 있다. 수동으로 실행을 하거나, Jenkins RestApi를 이용해서 실행을 할 수 있지만 주로 정해진 시간 즉, 스케쥴링에 의해 실행되곤 한다. 스케쥴링의 가장 작은 단위는 1분단위 배치도 있기 때문에 24시간 멈추지 않고 실행되고 있다고 무방하다. 하지만 배치 모듈이 수정되고, 배포를 하기 위해서는 다음과 같은 시나리오로 진행이 된다.
 Jenkins 설정의 끄기전 준비 를 실행하여 더이상 Jenkins에 의해 Spring batch 모듈(이하 Job)이 실행되지 않도록 한다. 새로운 Job은 더이상 실행되지 않지만 이미 실행중이였던 Job 은 강제로 중단을 하거나 Job 이 끝날때까지 기다린다. 실행중인 Job이 없을 경우 이제 배포를 진행한다. 배포가 완료되면 Jenkins 설정의 끄기전 준비를 해제한다.  실행중인 Job이 안끝나면 마냥 기다릴텐가? 출처 : https://m.post.naver.com/viewer/postView.nhn?volumeNo=14100660&amp;memberNo=2032633" 실행중인 Job이 안끝나면 마냥 기다릴텐가? 출처 : https://m.post.naver.com/viewer/postView.nhn?volumeNo=14100660&amp;memberNo=2032633  실행되는 Job을 중단하지 못하는 상황 즉, 실행중에 중단하면 트랜잭션이 깨져 무조건 기다려야만 하는 상황이라면 배포 또한 계속 지연될 수 밖에 없는 상황인 것이다. Spring boot에 java config 를 활용하고 딱 jar 파일 하나를 실행하는 방식이라면 jar파일을 바꿔치기 하는 식으로 고민을 해볼수도 있을것 같다. 하지만 Legacy 코드가 아직 존재하여 일반 Spring 에 xml 로 config 하는 방식으로 운영중이라 jar파일 하나만 바꿔치기 하기엔 무리가 있는 상황.
은총알처럼 어디에서나 사용이 가능한 만병통치약 같은 방법은 없다. 언제나 그랬듯 현재 시스템(xml config 방식)에 가장 최적화된 방법, 그리고 java config 방식에서도 사용이 가능할것 같은 방법을 생각해 보았다.
무중단 배포를 가능케 하는 3가지 핵심 1. 배포를 매번 새로운 경로에 배포한다. 각 회사마다, 그리고 서비스마다 정말 다양한 배포 시스템이 있다. 그들의 공통점은 원격서버의 특정 경로에 빌드된 파일들을 밀어 넣어준다는 것. 시나리오는 다음과 같다.
 배포할때마다 별도의 디렉토리를 생성한뒤 심볼릭 링크를 연결해준다. 배포는 1에서 연결한 심볼릭 링크에 배포되도록 설정, 결국 매번 만들어지는 디렉토리에 배포가 되게 된다.  여기서 중요한점은 &ldquo;배포할 때마다 새로운 디렉토리에 배포가 된다&rdquo; 와 배포시에는 항상 심볼릭 링크에만 배포를 하면 되기 때문에 &ldquo;배포시스템이 새로 만들어지는 디렉토리의 경로를 몰라도 무방하다&quot;는 점이다.
#!/bin/sh cd /~~~/deploy/ # 임시 디렉토리 DIRECTORY_NAME=batch_$(/bin/date +%Y%m%d%H%M%S) mkdir $DIRECTORY_NAME 위 쉘 스크립트를 실행하면 batch_20191012205218 와 같은 디렉토리가 생성이 된다. 심볼릭 링크 관련해서는 바로 아래 이어서 설명하겠다.
2. 심볼릭 링크의 원래 링크를 즉시 변경 보통 심볼릭 링크 (즉, 바로가기) 의 경로를 변경하기 위해서는 아래처럼 지웠다가 삭제하는 식으로 했었는데
$ mkdir directory_a $ mkdir directory_b $ ln -s directory_a asdf $ ll asdf -&gt; directory_a directory_a directory_b # directory_a 에서 directory_b 로 바꾸는 경우 (심볼릭 링크 자체를 삭제하고 다시 심볼릭 링크 생성) $ rm asdf $ ln -s directory_b asdf $ ll asdf -&gt; directory_b directory_a directory_b 이렇게 되면 삭제하고 ~ 다시 만들어지는 타이밍에 배포가 되거나 실행이 되는 즉, 해당 경로에 엑세스 하는 경우 이전의 경로를 바라본다거나 의도했던 방식으로 실행이 되지 않는 상황이 발생한다. (찰나의 타이밍 이지만 필자는 이러한 문제로 이전의 경로를 바라보는 문제가 발생했었다.) 그래서 ln 의 옵션중인 -Tfs옵션으로 즉시 변경을 해주도록 하자. (ln man 참고)
# 만든 임시 디렉토리로 배포될수 있도록 설정한다.]]></description></item></channel></rss>